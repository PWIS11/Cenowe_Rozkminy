---
title: "Analiza cen mieszkań w Polsce"
date: "`r Sys.Date()`"
author: "Piotr Wiśniewski - lider zespołu, Izabela Reszka, Klaudia Woźniak"
output:
  html_document:
    theme: cerulean
    highlight: tango
    highlight_color: "goldenrod"
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
## Global options
knitr::opts_chunk$set(cache = TRUE)
# Instalacja Pakietów
if (!requireNamespace("httr", quietly = TRUE)) install.packages("httr")
if (!requireNamespace("jsonlite", quietly = TRUE)) install.packages("jsonlite")
if (!requireNamespace("tidygeocoder", quietly = TRUE)) install.packages("tidygeocoder")
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
if (!requireNamespace("sf", quietly = TRUE)) install.packages("sf")
if (!requireNamespace("ggplot2", quietly = TRUE)) install.packages("ggplot2")
if (!requireNamespace("scales", quietly = TRUE)) install.packages("scales")
if (!requireNamespace("tidyverse", quietly = TRUE)) install.packages("tidyverse")
if (!requireNamespace("naniar", quietly = TRUE)) install.packages("naniar")
if (!requireNamespace("VIM", quietly = TRUE)) install.packages("VIM")
if (!requireNamespace("outliers", quietly = TRUE)) install.packages("outliers")
if (!requireNamespace("caret", quietly = TRUE)) install.packages("caret")
if (!requireNamespace("mice", quietly = TRUE)) install.packages("mice")
if (!requireNamespace("gridExtra", quietly = TRUE)) install.packages("gridExtra")
if (!requireNamespace("dlookr", quietly = TRUE)) install.packages("dlookr")
if (!requireNamespace("validate", quietly = TRUE)) install.packages("validate")

```

```{r libraries, include=FALSE}
library(httr)
library(jsonlite)
library(tidygeocoder)
library(dplyr)
library(sf)
library(ggplot2)
library(scales)
library(tidyverse)
library(naniar)
library(VIM)
library(outliers)
library(caret)
library(mice)
library(gridExtra)
library(dlookr)
library(validate)
```

# **Cel projektu**

Celem naszego projektu jest analiza cen mieszkań w największych miastach Polski, uwzględniając różnorodne czynniki, które mogą wpływać na wartość nieruchomości. Wykorzystamy metody analizy danych, aby odpowiedzieć na kluczowe pytania, takie jak:

-   *Od czego zależy cena mieszkań?*

-   *Jakie różnice w cenach występują pomiędzy miastami?*

-   *Czy odległość od centrum lub interesujących miejsc (POI) ma znaczenie dla wartości nieruchomości?*

-   *Które cechy mieszkań (np. liczba pokoi, stan, udogodnienia) są najbardziej cenione?*

## **Analizy w projekcie**

Planujemy zastosowanie narzędzi analizy danych oraz wizualizacji, aby lepiej zrozumieć rynek nieruchomości w Polsce. Nasze analizy obejmą:

-   Badanie zależności między cechami mieszkań (takimi jak lokalizacja, powierzchnia, liczba pokoi) a ich ceną.

-   Porównanie cen nieruchomości pomiędzy największymi polskimi miastami, w celu wykazania kluczowych różnic regionalnych.

-   Modelowanie predykcyjne, które pozwoli oszacować cenę mieszkań na podstawie wybranych zmiennych, takich jak odległość od centrum czy stan mieszkania.

-   Wykorzystanie interaktywnych wizualizacji, takich jak mapy i wykresy, aby przedstawić wyniki w przystępny sposób.

### **Hipotezy i oczekiwane wyniki**

1.  **Odległość od centrum miasta:** Zakładamy, że im bliżej centrum, tym wyższa cena mieszkań, choć siła tego wpływu może różnić się w zależności od miasta.

2.  **Cechy nieruchomości:** Udogodnienia takie jak balkon, winda czy miejsce parkingowe znacząco podnoszą wartość mieszkań, zwłaszcza w dużych miastach.

3.  **Różnice regionalne:** Miasta o wyższym poziomie urbanizacji i rozwiniętej infrastrukturze (np. Warszawa, Kraków, Wrocław) mają wyższe ceny mieszkań w porównaniu do mniejszych miejscowości.

4.  **Rok budowy:** Starsze mieszkania, wymagające remontu, są z reguły tańsze, chyba że znajdują się w prestiżowych lokalizacjach.

Podsumowując, oczekujemy, że nasze analizy wskażą najważniejsze czynniki wpływające na ceny mieszkań oraz umożliwią stworzenie użytecznych modeli predykcyjnych, które mogą wspierać decyzje zakupowe lub inwestycyjne.

## **Opis danych**

Zbiór danych pochodzi z ofert sprzedaży i wynajmu mieszkań z 15 największych polskich miast, zgromadzonych w czerwcu 2024 roku. Dane te obejmują szerokie spektrum cech nieruchomości oraz dodatkowe informacje z Open Street Map, które pozwalają uwzględnić kontekst sąsiedztwa mieszkań.

**Miasta w zbiorze danych:** Warszawa, Łódź, Kraków, Wrocław, Poznań, Gdańsk, Szczecin, Bydgoszcz, Lublin, Katowice, Białystok, Częstochowa.

**Główne pola w zbiorze danych:**

-   ***Lokalizacja i charakterystyka nieruchomości:***

    -   Miasto, typ budynku, wielkość w metrach kwadratowych, liczba pokoi, piętro, rok budowy.

-   ***Informacje kontekstowe:***

    -   Odległość od centrum miasta, liczba interesujących punktów w promieniu 500 metrów (np. szkoły, apteki, restauracje) oraz odległość do najbliższego punktu.

-   ***Cechy nieruchomości:***

    -   Stan mieszkania, rodzaj własności, obecność udogodnień (np. winda, balkon, miejsce parkingowe, ochrona).

-   ***Cena ofertowa:***

    -   Cena sprzedaży lub miesięczny czynsz.

## **Dane dodatkowe**

W celu wykonania bardziej szczegółowej analizy zdecydowaliśmy się wzbogacić nasz zbiór o **granice administracyjne województw**. Dane te zostały pobrane z pliku **`ms_A01_Granice_wojewodztw`** i umożliwiły przypisanie każdego miasta do odpowiedniego województwa.

### **Cel dodania danych:**

-   **Przypisanie lokalizacji mieszkań do województw**,\
-   **Przeprowadzenie analiz regionalnych**, aby lepiej zrozumieć różnice w cenach i cechach mieszkań w różnych częściach Polski.

Dzięki temu możliwe jest nie tylko szczegółowe badanie rynku nieruchomości na poziomie miast, ale także **porównanie wyników w kontekście regionalnym**.

## **Znaczenie projektu**

Rynek nieruchomości jest dynamiczny i podlega wpływowi wielu czynników, takich jak lokalizacja, liczba pokoi, dostępność udogodnień czy bliskość kluczowych miejsc. Analiza tych danych pozwoli lepiej zrozumieć mechanizmy kształtowania się cen mieszkań oraz stworzyć narzędzia wspomagające decyzje zakupowe i inwestycyjne.

```{r wstepna_obrobka_danych, echo=FALSE}
dane <- read.csv("apartments_pl_2024_06.csv", sep = ",", header = TRUE)

# Zmiana id na liczby rosnące, zaczynające się od cyfry 1
dane$id <- 1:nrow(dane)

# Zamiana pustych ciągów na NA
dane[dane == ""] <- NA
```

# **Data validation**
```{r weryfikacja_logicznej_spójności_danych}

# Definiowanie reguł walidacyjnych 

rules <- validator(
  "Piętro > Liczba kondygnacji" = floor <= floorCount,                                    # Piętro nie większe niż liczba kondygnacji
  "Rok budowy <= 2024" = buildYear <= 2024,                                               # Rok budowy nie większy niż rok bieżący
  "Rok budowy > 1600" = buildYear > 1600,                                                 # Rok budowy późniejszy niż 1600
  "Piętro >= 0" = floor >= 0,                                                             # Piętro nie może być ujemne
  "Liczba kondygnacji >= 0" = floorCount >= 0,                                            # Liczba kondygnacji nie może być ujemna
  "Liczba pokoi > 0" = rooms > 0,                                                         # Liczba pokoi większa niż 0
  "Liczba pokoi <= 15" = rooms <= 15,                                                     # Liczba pokoi nie większa niż 15
"Obecność windy w budynku z 0 kondygnacjami" = !(floorCount == 0 & hasElevator == "yes")  # Sprawdzenie, czy budynek z 0 kondygnacjami ma windę

)

out <- confront(dane, rules)

rules_names <- c("Piętro > Liczba kondygnacji", "Rok budowy <= 2024", "Rok budowy > 1600", 
                 "Piętro >= 0", "Liczba kondygnacji >= 0", "Liczba pokoi > 0", "Liczba pokoi <= 15","Obecność windy w budynku z 0 kondygnacjami")
expressions <- c("floor <= floorCount", "buildYear <= 2024", "buildYear > 1600", 
                 "floor >= 0", "floorCount >= 0", "rooms > 0", "rooms <= 15", "!(floorCount == 0 & hasElevator == 'yes')")

# Pobieranie wyników walidacji i obliczanie liczby spełnionych i niespełnionych reguł walidacyjnych

results <- lapply(c("Piętro...Liczba.kondygnacji", "Rok.budowy....2024", "Rok.budowy...1600", 
                    "Piętro....0", "Liczba.kondygnacji....0", "Liczba.pokoi...0", "Liczba.pokoi....15","Obecność.windy.w.budynku.z.0.kondygnacjami"), 
                  function(x) out$`._value`[[x]])

passes <- sapply(results, sum)
nNA <- sapply(results, function(x) sum(!x))

# Wyniki walidacji
wyniki_walidacji <- data.frame(
  reguła = rules_names,
  badane_obserwacje = rep(21501, 8),
  obserwacje_spełniające_regułę = passes,
  obserwacje_niespełniające_reguły = nNA,
  wyrażenie_reguły = expressions
)

# Wykres wyników walidacji z podziałem na reguły
plot(out)

# Wykres kołowy dla obserwacji "Piętro > liczba kondygnacji"
data <- data.frame(
  category = c("Spełniające regułę", "Niespełniające reguły"),
  count = c(20956, 545)
)

ggplot(data, aes(x = "", y = count, fill = category)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Podział obserwacji dla reguły: Piętro > Liczba kondygnacji") +
  theme_minimal() +
  theme(
    axis.text = element_blank(), 
    axis.ticks = element_blank(), 
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    legend.title = element_blank(),
    plot.margin = margin(20, 20, 20, 20),
    panel.grid = element_blank(),
    panel.border = element_blank()
  ) +
  geom_text(aes(label = paste0(count, " (", round(count / sum(count) * 100, 1), "%)")),
            color = "white", size = 6, fontface = "bold", 
            position = position_stack(vjust = 0.5)) +
  scale_fill_manual(values = c("mediumpurple", "aquamarine3"))



```
 Walidacja danych to proces, którego celem jest weryfikacja, czy dane spełniają określone kryteria, zapewniając ich poprawność, spójność oraz integralność. Jego zadaniem jest upewnienie się, że dane są zgodne z wymaganiami jakościowymi i formatowymi, które są kluczowe dla dalszego przetwarzania i analizy. W ramach tego procesu zdefiniowaliśmy i zastosowaliśmy reguły walidacyjne, mające na celu analizę spójności logicznej badanych zmiennych. Przyjęte zasady pozwalają na dokładną weryfikację poprawności danych, zapewniając ich zgodność z określonymi kryteriami logicznymi.
 1) Piętro (floor) nie może być większe niż liczba kondygnacji (floorCount).
 2) Rok budowy (buildYear) nie może być późniejszy niż bieżący rok (2024).
 3) Rok budowy musi być późniejszy niż 1600.
 4) Piętro (floor) i liczba kondygnacji (floorCount) muszą być większe lub równe 0.
 5) Liczba pokoi (rooms) musi być większa niż 0 i nie może przekraczać 15.
 6) Jeżeli liczba kondygnacji (floorCount) wynosi 0, to nie powinno być w takim budynku windy (hasElevator).

W procesie walidacji danych większość reguł została spełniona, jednak w przypadku jednej reguły, dotyczącej zgodności floor i floorCount, wykryto 545 nieprawidłowych obserwacji, które wymagają dalszej analizy i korekty. Wartości floor nie powinny przekraczać wartości floorCount, co jest kluczowe dla spójności danych. Pozostałe reguły zostały prawidłowo zastosowane i nie wykryto żadnych innych istotnych problemów w analizowanych danych. Błędy w danych "floor" i "floorCount" mogą być spowodowane błędnie uzupełnionymi wartościami lub niektualnymi danymi (budynki mogły zmienić liczbę kondygnacji po modernizacji). 


```{r walidacja_i_korekta_wartości;floor_floorCount,flitracja_duplikatów}

# Błędne obserwacje - filtracja 
bledne_obserwacje <- dane %>% filter(floor > floorCount)

# Korekta błędnych wartości
dane <- dane %>% mutate(floorCount = ifelse(floorCount < floor, floor, floorCount))

# Sprawdzanie duplikatów
zduplikowane_wiersze <- dane[duplicated(dane), ]
```

W wyniku analizy danych stwierdzono, że w niektórych przypadkach wartość floor była większa niż liczba floorCount, co jest logicznie nieprawidłowe. Aby poprawić te błędy, przyjęto zasadę, że w takich sytuacjach wartość liczby kondygnacji (floorCount) zostanie ustawiona na wartość piętra (floor).

Jeśli wartość liczby kondygnacji była równa lub większa od wartości piętra, dane pozostały niezmienione. Taka korekta zapewnia spójność danych i eliminuje przypadki, w których piętro przewyższa liczbę kondygnacji w budynku.Nie znaleziono duplikatów wierszy w danych. 


# **Data wrangling**
```{r weryfikacja_typów_danych}

# Sprawdzenie struktury danych i sptawdzenie pierwszych kilku wierszy danych
str(dane)
head(dane)

# Sprawdzenie i weryfikacja typów danych i liczby unikalnych wartości w każdej kolumnie
typy_danych <- sapply(dane, class) 
unikalne_wartosci <- sapply(dane, function(x) length(unique(x)))

tabela_typów_danych <- data.frame(
  Kolumna = names(dane),           
  Typ = typy_danych,              
  Liczba_unikalnych = unikalne_wartosci 
)

# Podsumowanie ile kolumn jest każdego typu
liczba_numeric <- sum(typy_danych == "numeric")
liczba_character <- sum(typy_danych == "character")
liczba_factor <- sum(typy_danych == "factor")
liczba_integer <- sum(typy_danych == "integer")
liczba_logical <- sum(typy_danych == "logical")

rodzaje_danych <- data.frame(
  Typ = c("Numeric", "Character", "Factor", "Integer", "Logical"),
  Liczba_kolumn = c(liczba_numeric, liczba_character, liczba_factor, liczba_integer, liczba_logical)
)


```
Zbiór danych składa się z 28 kolumn, które charakteryzują się następującymi typami: 18 zmiennych numerycznych (typ numeric), 6 zmiennych tekstowych (typ character), 3 zmiennymi kategorycznymi (typ factor), 2 zmiennymi całkowitymi (typ integer) oraz brakiem zmiennych logicznych. 

Zmienne numeryczne, takie jak squareMeters, price czy centreDistance, mają dużą liczbę unikalnych wartości, co sugeruje, że są to dane ciągłe, które będą odpowiednie do analizy regresyjnej. Zmienne kategoryczne, takie jak type, ownership czy buildingMaterial, mogą być traktowane jako zmienne typu factor i wykorzystane w analizach klasyfikacyjnych. Z kolei kolumny z typem integer, jak np. price, również mogą być używane w analizach numerycznych.

Dzięki tej weryfikacji możemy odpowiednio przygotować dane do dalszej analizy i modelowania. Zmienne numeryczne będą wykorzystywane w analizach regresyjnych, zmienne typu factor w klasyfikacyjnych, a zmienne character mogą wymagać kodowania na typ factor, aby mogły być wykorzystane w dalszej analizie. Na podstawie tej analizy możemy przejść do przygotowania danych do modelowania, dobierając odpowiednie metody przetwarzania, takie jak kodowanie zmiennych kategorycznych, normalizację zmiennych numerycznych czy tworzenie nowych zmiennych, w zależności od typu danych i celu analizy.



## **Obserwacje brakujące**

Do analizy brakujących danych zdecydowaliśmy się wykorzystać zarówno wizualizacje które pozwolą zrozumieć skalę oraz potencjalne przyczyny braków w zbiorze danych. Wizualizacje, takie jak **wykresy słupkowe** prezentujące procent brakujących wartości w poszczególnych zmiennych oraz graficzne przedstawienie wzorców braków, umożliwiają szybkie zidentyfikowanie kolumn najbardziej dotkniętych problemem brakujących danych. Dodatkowo zastosowanie **macierzy braków** pozwala na analizę współwystępowania braków pomiędzy zmiennymi, co może wskazać na możliwe zależności w danych.

Na podstawie klasyfikacji braków danych (MCAR, MAR, MNAR) możemy lepiej zrozumieć przyczyny ich występowania.

-   **MCAR (Missing Completely At Random)**: Braki w kolumnach takich jak hasElevator i collegeDistance są losowe i wynikają z technicznych pominięć w zbieraniu danych.

-   **MAR (Missing At Random)**: Braki w kolumnach condition, buildingMaterial, oraz floor wynikają z powiązań między zmiennymi, np. type i floorCount.

-   **MNAR (Missing Not At Random)**: Braki w type mogą wynikać z mechanizmu niechęci podawania wartości (np. dla mieszkań luksusowych).

Dzięki tym wstępnym analizom możliwe jest odpowiednie dobranie metod imputacji (np. medianą, modą lub bardziej zaawansowanymi metodami), a także ewentualne usunięcie zmiennych, w których braki są zbyt liczne i niemożliwe do uzupełnienia bez znaczącej utraty jakości danych.

```{r obserwacje_brakujace_wykresy, echo=FALSE, comment=FALSE}
missing_summary <- miss_var_summary(dane)

ggplot(missing_summary, aes(x = reorder(variable, -pct_miss), y = pct_miss)) +
  geom_bar(stat = "identity", fill = "plum2") +
  coord_flip() +
  labs(title = "Procent brakujących wartości w kolumnach",
       x = "Zmienne",
       y = "Procent braków (%)") +
  theme_minimal()
```

```{r obserwacje_brakujace_wykresy_2, echo=FALSE}
suppressMessages({
  vismiss <- vis_miss(dane) +
    scale_fill_manual(values = c("lightyellow", "orchid3"),
                      name = "Status danych",
                      labels = c("Dane obecne", "Braki danych")) +
    labs(
      title = "Braki danych w zbiorze",
      x = "Zmienne",
      y = "Obserwacje"
    ) +
    theme_minimal(base_size = 10) + 
    theme(
      plot.title = element_text(hjust = 0.5),
      axis.text.x = element_text(angle = 45, hjust = 0.2)
    )
  
  print(vismiss)
})
```

Analiza brakujących danych wskazuje, że kolumny w zbiorze można podzielić na kilka grup pod względem liczby braków:

-   **Bardzo duża liczba braków:** condition (74.0%) i buildingMaterial (40.9%). Ze względu na ich wysoką niekompletność zdecydowaliśmy się usunąć kolumnę condition, a dla buildingMaterial zastosujemy imputację najczęstszą wartością.

-   **Umiarkowana liczba braków:** type (20.5%), floor (16.6%), buildYear (15.7%). Uzupełnimy brakujące wartości odpowiednio metodą najczęstszej wartości dla zmiennych kategorycznych (type) oraz medianą dla zmiennych liczbowych (floor, buildYear).

-   **Niewielka liczba braków:** Kolumny takie jak hasElevator (4.46%) czy collegeDistance (2.72%) zostaną uzupełnione odpowiednio modą i medianą.

-   **Bardzo mała liczba braków:** Pozostałe kolumny z mniej niż 1% braków zostaną imputowane prostymi metodami (medianą lub najczęstszą wartością).

-   **Kolumny bez braków:** Pozostałe zmienne, takie jak price, squareMeters czy rooms, są kompletne i nie wymagają dodatkowych działań.

```{r wzorce_brakow, echo=FALSE, warning=FALSE, message=FALSE}
# Zwiększenie rozmiaru wykresu
options(repr.plot.width = 14, repr.plot.height = 10)

# Tworzenie wykresu z jeszcze mniejszymi czcionkami
aggr(dane, 
     col = c("lightyellow", "orchid3"), 
     numbers = TRUE, 
     sortVars = TRUE,
     labels = names(dane), 
     cex.axis = 0.4, # Zmniejszenie czcionki osi
     gap = 1.5,      # Zmniejszenie odstępów między elementami
     ylab = c("Procent braków", "Wzorce braków"))
```

### Imputacja medianą oraz modą

```{r Zastąpienie_braków_medianą_i_najczęstszą_wartością}
################################################################################

dane$floor<-imputate_na(dane, floor, method = "median")
dane$buildYear<-imputate_na(dane, buildYear, method = "median")
dane$collegeDistance<-imputate_na(dane, collegeDistance, method = "median")
dane$schoolDistance<-imputate_na(dane, schoolDistance, method = "median")
dane$pharmacyDistance<-imputate_na(dane, pharmacyDistance, method = "median")
dane$kindergartenDistance<-imputate_na(dane, kindergartenDistance, method = "median")
dane$clinicDistance<-imputate_na(dane, clinicDistance, method = "median")
dane$postOfficeDistance<-imputate_na(dane, postOfficeDistance, method = "median")
dane$restaurantDistance<-imputate_na(dane, restaurantDistance, method = "median")
dane$floorCount<-imputate_na(dane, floorCount, method = "median")

################################################################################

#table(na.omit(dane$type)) SPRAWDZENIE CZĘSTOSCI WYSTĘPOWANIA
#table(na.omit(dane$buildingMaterial)) SPRAWDZENIE CZĘSTOSCI WYSTĘPOWANIA
#table(na.omit(dane$hasElevator))

dane$type[is.na(dane$type)] <- "blockOfFlats"
dane$buildingMaterial[is.na(dane$buildingMaterial)] <- "brick"
dane$hasElevator[is.na(dane$hasElevator)] <- "yes"

dane$type <- factor(dane$type)
dane$buildingMaterial <- factor(dane$buildingMaterial)
dane$hasElevator <- factor(dane$hasElevator)

#dane$buildingMaterial<-imputate_na(dane, buildingMaterial, method = "mode") -----> wyskakuje błąd
################################################################################
dane$condition <- NA
dane <- subset(dane, select = -condition)
################################################################################
```

```{r Dodanie_dodatkowych_kolumn_cena_za_metr_wiek_mieszkania}
# Dodanie kolumny z ceną za metr kwadratowy
dane$pricePerSquareMeter <- dane$price / dane$squareMeters

# Dodanie kolumny z wiekiem mieszkania
currentYear <- format(Sys.Date(), "%Y")
dane$buildingAge <- ifelse(is.na(dane$buildYear), NA, as.numeric(currentYear) - dane$buildYear)
```

## **Obserwacje odstające**

Do analizy obserwacji odstających decydowaliśmy się użyć **wykresów pudełkowych**, ponieważ są one prostym i skutecznym narzędziem wizualizacyjnym, które pozwala szybko zidentyfikować wartości odstające. Dzięki nim poznamy wartości minimalne, maksymalne, mediane, kwartyle oraz ewentualne wartości wykraczające poza tzw. *wąsy*, czyli zakres między pierwszym a trzecim kwartylem powiększony. Każda z analizowanych zmiennych została przedstawiona na osobnym wykresie pudełkowym, co pozwala dokładnie przyjrzeć się rozkładowi poszczególnych cech, takich jak powierzchnia mieszkania, cena, cena za metr kwadratowy czy odległości od różnych punktów użyteczności publicznej. Dzięki temu można szybko zidentyfikować zmienne, które mogą zawierać nietypowe wartości i potencjalnie wpłynąć na dalsze analizy lub modelowanie danych.

Dodatkowo, aby potwierdzić statystycznie obecność obserwacji odstających zastosowaliśmy metodę Z-score oraz zbadaliśmy czy rozkład danych jest zbliżony do rozkładu normalnego.

-   Metoda **Z-score**, polega na identyfikowaniu obserwacji odstających na podstawie odchylenia standardowego od średniej. Wyraża się wzorem: $$
         Z = \frac{x - \bar{x}}{\sigma}
         $$ $x$: wartość obserwacji\
    $\overline{x}$: średnia dla danej zmiennej\
    $\sigma$: odchylenie standardowe.

**Skośność** jest statystyką umożliwiającą porównanie rozkładu analizowanej zmiennej z hipotetycznym rozkładem normalnym. Wskazuje na rozbieżności pomiędzy wartością średnią, a centrum danego rozkładu. Wyraża się wzorem:

$$\tilde{\mu}_3 = \frac{\sum_{i}^{N} (X_i - \bar{X})^3}{(N - 1) \cdot \sigma^3}$$

-   $\tilde{\mu}_3$ = skośność
-   $N$ = liczba zmiennych w rozkładzie
-   $X_i$ = losowa zmienna
-   $\bar{X}$ = średnia rozkładu
-   $\sigma$ = odchylenie standardowe.

Interpretacja jest następująca:

-   Rozkład prawoskośny -- skośność jest dodatnia, prawe ramię rozkładu jest wydłużone, wyniki poniżej średniej są przeważające w badanej próbce.

-   Rozkład symetryczny -- skośność wynosi 0, ogony rozkładu są identyczne w obu kierunkach. Jeśli znormalizowana kurtoza wynosi 0, rozkład jest zbliżony do rozkładu normalnego.

-   Rozkład lewoskośny -- skośność jest ujemna, lewe ramię rozkładu jest wydłużone, większość obserwacji w próbie ma wartości powyżej średniej.

### Wykresy pudełkowe

```{r zamiana_na_numeryczne, echo=FALSE}
dane$buildingAge <- as.numeric(dane$buildingAge)
dane$latitude <- as.numeric(dane$latitude)
dane$longitude <- as.numeric(dane$longitude)
dane$centreDistance <- as.numeric(dane$centreDistance)
dane$schoolDistance <- as.numeric(dane$schoolDistance)
dane$clinicDistance <- as.numeric(dane$clinicDistance)
dane$postOfficeDistance <- as.numeric(dane$postOfficeDistance)
dane$kindergartenDistance <- as.numeric(dane$kindergartenDistance)
dane$collegeDistance <- as.numeric(dane$collegeDistance)
dane$restaurantDistance <- as.numeric(dane$restaurantDistance)
dane$pharmacyDistance <- as.numeric(dane$pharmacyDistance)
dane$floorCount <- as.numeric(dane$floorCount)
```

```{r boxplot_odst, fig.height=10, fig.width=10, echo=FALSE, fig.show='hold'}
# Renderowanie pierwszej strony (9 wykresów)
par(mfrow = c(3, 3))  # Układ 3x3
boxplot(dane$squareMeters, main = "Square Meters", col = "skyblue")
boxplot(dane$price, main = "Price", col = "plum")
boxplot(dane$pricePerSquareMeter, main = "PricePerSquareMeter", col = "peachpuff")
boxplot(dane$rooms, main = "Rooms", col = "palegreen2")
boxplot(dane$floor, main = "Floors", col = "powderblue")
boxplot(dane$floorCount, main = "FloorCount", col = "thistle3")
boxplot(dane$buildingAge, main = "BuildingAge", col = "salmon")
boxplot(dane$centreDistance, main = "CentreDistance", col = "pink4")
boxplot(dane$schoolDistance, main = "SchoolDistance", col = "pink")
```


```{r boxplot_odst2, fig.height=7, fig.width=10, echo=FALSE, fig.show='hold'}
# Resetowanie układu
par(mfrow = c(2, 3))  # Układ 2x3 dla 6 miejsc

# Renderowanie drugiej strony (5 wykresów + puste miejsce)
boxplot(dane$clinicDistance, main = "ClinicDistance", col = "orange")
boxplot(dane$postOfficeDistance, main = "PostOfficeDistance", col = "coral")
boxplot(dane$kindergartenDistance, main = "KindergardenDistance", col = "lavender")
boxplot(dane$restaurantDistance, main = "RestaurantDistance", col = "khaki")
boxplot(dane$collegeDistance, main = "CollegeDistance", col = "indianred")
boxplot(dane$pharmacyDistance, main = "PharmacyDistance", col = "lavenderblush2")
```



#### **Interpretacja wyników wykresów pudełkowych**

Przeprowadzona analiza wykresów pudełkowych pozwoliła na dokładne przyjrzenie się rozkładom badanych cech mieszkań, takich jak powierzchnia, cena, liczba pokoi oraz odległości do punktów użyteczności publicznej. Wykresy te umożliwiły identyfikację wartości **typowych** (mediana, kwartyle) oraz **wartości odstających**, które wykraczają poza zakres wyznaczony przez *wąsy*.\
Wartości odstające są szczególnie istotne, ponieważ mogą wskazywać na specyficzne obserwacje, takie jak:

-   **Nieruchomości luksusowe** lub o nietypowej wielkości i cenie,\
-   **Mieszkania położone w trudno dostępnych lokalizacjach**,\
-   **Nieruchomości w starszych budynkach** lub obszarach o słabo rozwiniętej infrastrukturze.

Poniżej przedstawiono szczegółową interpretację wyników dla każdej z analizowanych zmiennych.

------------------------------------------------------------------------

**Square Meters (Powierzchnia mieszkań):**\
- Mediana powierzchni wynosi około **50-60 m²**.\
- Większość mieszkań mieści się w zakresie **40-80 m²**.\
- **Wartości odstające** powyżej **100 m²** wskazują na większe apartamenty lub luksusowe nieruchomości.

**Price (Cena mieszkań):**\
- Mediana ceny mieszkań wynosi około **750 tys. zł**.\
- Typowe wartości mieszczą się w przedziale **500 tys. – 1 mln zł**.\
- Liczne **wartości odstające** powyżej **2,5 mln zł** sugerują obecność luksusowych nieruchomości w analizowanym zbiorze.

**PricePerSquareMeter (Cena za m²):**\
- Mediana wynosi około **15 000 zł/m²**, a większość wartości mieści się w zakresie **10 000 – 20 000 zł/m²**.\
- **Wartości odstające** przekraczające **30 000 zł/m²** mogą wynikać z mieszkań położonych w bardzo prestiżowych lokalizacjach.

**Rooms (Liczba pokoi):**\
- Typowe mieszkania mają **2-3 pokoje**, co potwierdza mediana.\
- **Wartości odstające** (4-6 pokoi) mogą wskazywać na większe mieszkania lub apartamenty rodzinne.

**Floors (Piętro):**\
- Mediana piętra to około **2**.\
- Większość mieszkań znajduje się na **1-5 piętrze**.\
- **Wartości odstające** powyżej **15 piętra** sugerują obecność mieszkań w wieżowcach.

**FloorCount (Liczba pięter w budynku):**\
- Typowe budynki mają **4-6 pięter**.\
- **Wartości odstające** powyżej **15 pięter** wskazują na obecność wysokich budynków mieszkalnych.

**BuildingAge (Wiek budynku):**\
- Mediana wieku budynków wynosi około **50 lat**.\
- Budynki mające więcej niż **100 lat** to **wartości odstające**, co sugeruje obecność starszych, często zabytkowych nieruchomości.

**CentreDistance (Odległość od centrum):**\
- Typowa odległość to **2-8 km**.\
- **Wartości odstające** powyżej **15 km** wskazują na nieruchomości położone na przedmieściach lub w odległych lokalizacjach.

**SchoolDistance (Odległość od szkoły):**\
- Większość szkół znajduje się w odległości **do 1 km**.\
- **Wartości odstające** powyżej **4 km** mogą świadczyć o gorszej dostępności edukacji w analizowanych lokalizacjach.

**ClinicDistance (Odległość od kliniki):**\
- Kliniki są najczęściej położone **do 1 km** od mieszkań.\
- **Wartości odstające** powyżej **3 km** wskazują na obszary o niższym dostępie do opieki zdrowotnej.

**PostOfficeDistance (Odległość od poczty):**\
- Typowa odległość wynosi **0-1 km**.\
- **Wartości odstające** powyżej **4 km** mogą wynikać z mniej zurbanizowanych obszarów.

**KindergardenDistance (Odległość od przedszkola):**\
- Przedszkola znajdują się głównie **do 1 km** od mieszkań.\
- **Wartości odstające** powyżej **3 km** sugerują problemy z dostępem do usług dla rodzin z dziećmi.

**RestaurantDistance (Odległość od restauracji):**\
- Restauracje znajdują się typowo **do 1 km** od mieszkań.\
- **Wartości odstające** powyżej **5 km** wskazują na peryferyjne lokalizacje z ograniczoną ofertą gastronomiczną.

**CollegeDistance (Odległość od uczelni):**\
- Typowa odległość wynosi **1-2 km**.\
- **Wartości odstające** do **5 km** sugerują lokalizacje mniej centralne pod względem infrastruktury edukacyjnej.

**PharmacyDistance (Odległość od apteki):**\
- Apteki znajdują się zazwyczaj **do 1 km** od mieszkań.\
- **Wartości odstające** powyżej **4 km** wskazują na obszary o ograniczonym dostępie do usług farmaceutycznych.

------------------------------------------------------------------------

Analiza wykresów pudełkowych potwierdziła występowanie wartości odstających w każdej z badanych zmiennych. Są one szczególnie istotne, ponieważ mogą wskazywać na specyficzne segmenty rynku nieruchomości – luksusowe mieszkania, nieruchomości historyczne lub obszary z ograniczoną infrastrukturą.

Zidentyfikowane wartości odstające będą miały istotne znaczenie w dalszym modelowaniu oraz analizach statystycznych. Warto w kolejnych krokach rozważyć, czy te obserwacje powinny zostać zachowane jako istotne dla analizy, czy też przekształcone lub usunięte w zależności od kontekstu biznesowego i analitycznego.


### Skośność

<a id="centreDistancePlot"></a>
<a id="poiCountPlot"></a>
<a id="schoolDistancePlot"></a>
<a id="clinicDistancePlot"></a>
<a id="postOfficeDistancePlot"></a>
<a id="kindergartenDistancePlot"></a>
<a id="restaurantDistancePlot"></a>
<a id="collegeDistancePlot"></a>
<a id="pharmacyDistancePlot"></a>



```{r skosnosc, echo = FALSE, eval = TRUE, fig.height=6, fig.width=8}
par(mfrow = c(3, 3))  # Układ 3x3
hist(na.omit(dane$centreDistance), 
     probability = TRUE, 
     col = "plum1", 
     main = "Histogram - centreDistance", 
     xlab = "centreDistance")
curve(dnorm(x, mean = mean(na.omit(dane$centreDistance)), 
            sd = sd(na.omit(dane$centreDistance))), 
      col = "plum4", 
      lwd = 2, 
      add = TRUE)

# poiCount
hist(na.omit(dane$poiCount), 
     probability = TRUE, 
     col = "lightblue", 
     main = "Histogram - poiCount", 
     xlab = "poiCount")
curve(dnorm(x, mean = mean(na.omit(dane$poiCount)), 
            sd = sd(na.omit(dane$poiCount))), 
      col = "darkblue", 
      lwd = 2, 
      add = TRUE)

# schoolDistance
hist(na.omit(dane$schoolDistance), 
     probability = TRUE, 
     col = "lightgreen", 
     main = "Histogram - schoolDistance", 
     xlab = "schoolDistance")
curve(dnorm(x, mean = mean(na.omit(dane$schoolDistance)), 
            sd = sd(na.omit(dane$schoolDistance))), 
      col = "green4", 
      lwd = 2, 
      add = TRUE)

# clinicDistance
hist(na.omit(dane$clinicDistance), 
     probability = TRUE, 
     col = "lightpink", 
     main = "Histogram - clinicDistance", 
     xlab = "floorCount")
curve(dnorm(x, mean = mean(na.omit(dane$clinicDistance)), 
            sd = sd(na.omit(dane$clinicDistance))), 
      col = "violet", 
      lwd = 2, 
      add = TRUE)

# postOfficeDistance
hist(na.omit(dane$postOfficeDistance), 
     probability = TRUE, 
     col = "peachpuff", 
     main = "Histogram - postOfficeDistance", 
     xlab = "postOfficeDistance")
curve(dnorm(x, mean = mean(na.omit(dane$postOfficeDistance)), 
            sd = sd(na.omit(dane$postOfficeDistance))), 
      col = "orange1", 
      lwd = 2, 
      add = TRUE)

# kindergartenDistance
hist(na.omit(dane$kindergartenDistance), 
     probability = TRUE, 
     col = "lightyellow", 
     main = "Histogram - kindergartenDistance", 
     xlab = "kindergartenDistance")
curve(dnorm(x, mean = mean(na.omit(dane$kindergartenDistance)), 
            sd = sd(na.omit(dane$kindergartenDistance))), 
      col = "yellow2", 
      lwd = 2, 
      add = TRUE)
# restaurantDistance
hist(na.omit(dane$restaurantDistance), 
     probability = TRUE, 
     col = "grey", 
     main = "Histogram - restaurantDistance", 
     xlab = "restaurantDistance")
curve(dnorm(x, mean = mean(na.omit(dane$restaurantDistance)), 
            sd = sd(na.omit(dane$restaurantDistance))), 
      col = "grey1", 
      lwd = 2, 
      add = TRUE)
# collegeDistance
hist(na.omit(dane$collegeDistance), 
     probability = TRUE, 
     col = "red4", 
     main = "Histogram - collegeDistance", 
     xlab = "collegeDistance")
curve(dnorm(x, mean = mean(na.omit(dane$collegeDistance)), 
            sd = sd(na.omit(dane$collegeDistance))), 
      col = "tomato1", 
      lwd = 2, 
      add = TRUE)
# pharmacyDistance
hist(na.omit(dane$pharmacyDistance), 
     probability = TRUE, 
     col = "skyblue1", 
     main = "Histogram - pharmacyDistance", 
     xlab = "pharmacyDistance")
curve(dnorm(x, mean = mean(na.omit(dane$pharmacyDistance)), 
            sd = sd(na.omit(dane$pharmacyDistance))), 
      col = "dodgerblue3", 
      lwd = 2, 
      add = TRUE)
```
<a id="buildingAgePlot"></a>
<a id="squareMetersPlot"></a>
<a id="pricePlot"></a>
<a id="floorPlot"></a>
<a id="floorCountPlot"></a>
<a id="buildYearPlot"></a>

```{r skosnosc_hist2, echo = FALSE, eval = TRUE, fig.height=4, fig.width=8}
par(mfrow = c(2, 3))  # Układ 3x3
# postOfficeDistance
hist(na.omit(dane$buildingAge), 
     probability = TRUE, 
     col = "palegoldenrod", 
     main = "Histogram - buildingAge", 
     xlab = "buildingAge")
curve(dnorm(x, mean = mean(na.omit(dane$buildingAge)), 
            sd = sd(na.omit(dane$buildingAge))), 
      col = "palegreen3", 
      lwd = 2, 
      add = TRUE)

# squareMeters
hist(na.omit(dane$squareMeters), 
     probability = TRUE, 
     col = "deeppink", 
     main = "Histogram - squareMeters", 
     xlab = "squareMeters")
curve(dnorm(x, mean = mean(na.omit(dane$squareMeters)), 
            sd = sd(na.omit(dane$squareMeters))), 
      col = "deeppink4", 
      lwd = 2, 
      add = TRUE)

# price
hist(na.omit(dane$price), 
     probability = TRUE, 
     col = "antiquewhite", 
     main = "Histogram - price", 
     xlab = "price")
curve(dnorm(x, mean = mean(na.omit(dane$price)), 
            sd = sd(na.omit(dane$price))), 
      col = "indianred2", 
      lwd = 2, 
      add = TRUE)

# floor
hist(na.omit(dane$floor), 
     probability = TRUE, 
     col = "slategray2", 
     main = "Histogram - floor", 
     xlab = "floor")
curve(dnorm(x, mean = mean(na.omit(dane$floor)), 
            sd = sd(na.omit(dane$floor))), 
      col = "orchid", 
      lwd = 2, 
      add = TRUE)

# floorCount
hist(na.omit(dane$floorCount), 
     probability = TRUE, 
     col = "burlywood", 
     main = "Histogram - floorCount", 
     xlab = "floorCount")
curve(dnorm(x, mean = mean(na.omit(dane$floorCount)), 
            sd = sd(na.omit(dane$floorCount))), 
      col = "burlywood4", 
      lwd = 2, 
      add = TRUE)

# buildYear
hist(na.omit(dane$buildYear), 
     probability = TRUE, 
     col = "lightblue", 
     main = "Histogram - buildYear", 
     xlab = "buildYear")
curve(dnorm(x, mean = mean(na.omit(dane$buildYear)), 
            sd = sd(na.omit(dane$buildYear))), 
      col = "darkblue", 
      lwd = 2, 
      add = TRUE)
```


#### **Interpretacja wyników histogramów**

Przeprowadzona analiza histogramów pozwoliła na dokładne przyjrzenie się rozkładom badanych cech mieszkań, takich jak powierzchnia, cena, liczba pięter oraz odległości do punktów użyteczności publicznej. Wykresy te umożliwiły identyfikację wartości **typowych** (dominanty, gęstość wartości) oraz **wartości odstających**, które znajdują się na krańcach rozkładów.  
Linie rozkładu normalnego, nałożone na histogramy, stanowią dodatkowy punkt odniesienia do oceny kształtu rozkładów. Pozwalają one zidentyfikować:  

- **Odstępstwa od normalności**, takie jak skośność czy wielomodalność,  
- **Stopień zgodności rozkładów empirycznych z teoretycznym rozkładem normalnym**,  
- **Przesunięcia względem środka rozkładu** sugerujące koncentrację danych.  

---

**[centreDistance](#centreDistancePlot):**
- Rozkład jest **prawoskośny** z koncentracją wartości w zakresie **2-8 km**.  
- Linia rozkładu normalnego pokazuje, że rozkład empiryczny jest odchylony w prawo.  
- Wartości powyżej **10 km** stanowią odstępstwa, które wskazują na nieruchomości w peryferyjnych lokalizacjach, co jest nietypowe dla większości analizowanych danych.

**[poiCount](#poiCountPlot)** 
- Histogram pokazuje **wysoce prawoskośny** rozkład, gdzie większość obserwacji znajduje się poniżej **50**.  
- Linia rozkładu normalnego podkreśla duże odchylenie od symetrii, co sugeruje, że większość lokalizacji ma ograniczoną liczbę punktów użyteczności publicznej, natomiast pojedyncze przypadki z bardzo dużymi wartościami (powyżej **100**) są wyjątkami.

**[schoolDistance](#schoolDistancePlot)**  
- Rozkład odległości jest **prawoskośny**, z dominacją wartości **0-1 km**.  
- Linia normalna nie pasuje do rozkładu, co wskazuje na silną koncentrację danych blisko **0 km**.  
- Wartości odstające powyżej **3 km** sugerują lokalizacje z ograniczonym dostępem do szkół.

**[clinicDistance](#clinicDistancePlot)**  
- Histogram pokazuje **prawoskośny rozkład**, z większością wartości w przedziale **do 1 km**.  
- Linia rozkładu normalnego wyraźnie nie oddaje koncentracji danych w niższych wartościach.  
- Wartości powyżej **3 km** sugerują trudniejszy dostęp do opieki zdrowotnej w mniej zurbanizowanych obszarach.

**[postOfficeDistance](#postOfficeDistancePlot)**  
- Rozkład jest **prawoskośny**, z typowymi wartościami **0,5–1 km**.  
- Linia rozkładu normalnego wskazuje na istotne odchylenie od normalności, co podkreśla silne skupienie danych w niższych przedziałach.

**[restaurantDistance](#restaurantDistancePlot)**  
- Histogram ujawnia koncentrację wartości w zakresie **do 1 km** z pojedynczymi przypadkami powyżej **3 km**.  
- Przesunięcie względem linii normalnej podkreśla ograniczoną liczbę nieruchomości o znacznej odległości od restauracji.

**[collegeDistance](#collegeDistancePlot)**  
- Wartości typowe mieszczą się w przedziale **1–2 km**, natomiast histogram jest **lekko prawoskośny**.  
- Linia rozkładu normalnego dobrze przybliża dane w środkowej części, jednak widać odchylenia w wyższych wartościach (powyżej **4 km**).

**[pharmacyDistance](#pharmacyDistancePlot)** 
- Histogram jest **silnie prawoskośny**, z wartościami typowymi **do 1 km**.  
- Linia normalna nie jest dopasowana, co sugeruje, że rozkład empiryczny jest skupiony na jednym krańcu.

---

**[squareMeters](#squareMetersPlot)** 
- Rozkład powierzchni mieszkań jest **prawoskośny**, z wartościami dominującymi w przedziale **40–80 m²**.  
- Linia rozkładu normalnego sugeruje większą symetrię niż istnieje w danych.  
- **Wartości odstające** powyżej **100 m²** wskazują na duże apartamenty, które są nietypowe.

**[price](#pricePlot)**
- Histogram jest **wysoce prawoskośny**, z typowymi cenami **500 tys. – 1 mln zł**.  
- Rozkład empiryczny jest znacznie przesunięty względem linii normalnej, co podkreśla nierównomierną strukturę cen na rynku.

**[floor](#floorPlot)** 
- Większość mieszkań znajduje się na **1-5 piętrze**.  
- Linia rozkładu normalnego odbiega od rzeczywistego kształtu, który jest **skośny**, z kilkoma wartościami odstającymi powyżej **15 piętra**.

**[floorCount](#floorCountPlot)** 
- Rozkład pokazuje, że typowe budynki mają **4-6 pięter**.  
- Linia normalna nie oddaje koncentracji w niskich wartościach oraz odstępstw w wysokich budynkach.

**[buildingAge](#buildingAgePlot)** 
- Histogram wskazuje, że większość budynków ma mniej niż **50 lat**.  
- Rozkład jest prawoskośny, a linia normalna sugeruje większą symetrię niż rzeczywiście istnieje.

**[buildYear](#buildYearPlot)** 
- Rozkład pokazuje koncentrację budynków wybudowanych po **1950 roku**.  
- Linia normalna dobrze dopasowuje się do danych, jednak rozkład jest lekko przesunięty ku nowszym budynkom.

---
 
Analiza histogramów, w połączeniu z linią rozkładu normalnego, dostarczyła następujących wniosków:  
- **Większość rozkładów jest prawoskośna**, co sugeruje koncentrację wartości w niższych przedziałach oraz obecność kilku wartości odstających.  
- Linie normalne pozwoliły zidentyfikować rozbieżności między rozkładami empirycznymi a teoretycznym rozkładem normalnym.  
- **Wartości odstające** są widoczne w wielu zmiennych, zwłaszcza w powierzchni mieszkań, cenach oraz odległościach do punktów użyteczności publicznej.  

Wyniki te potwierdzają specyfikę rynku nieruchomości, gdzie typowe wartości są skoncentrowane w określonych zakresach, a odstępstwa wskazują na szczególne przypadki, które mogą być analizowane osobno.

### Z-score

```{r z-score, echo = FALSE}
# mean((dane$buildYear-mean(dane$buildYear))/sd(dane$buildYear))
# mean((dane$price-mean(dane$price))/sd(dane$price))
# mean((dane$squareMeters-mean(dane$squareMeters))/sd(dane$squareMeters))
# mean((dane$pricePerSquareMeter-mean(dane$pricePerSquareMeter))/sd(dane$pricePerSquareMeter))
# mean((dane$rooms-mean(dane$rooms))/sd(dane$rooms))
# mean((dane$floor-mean(dane$floor))/sd(dane$floor))
# mean((dane$floorCount-mean(dane$floorCount))/sd(dane$floorCount))
# mean((dane$centreDistance-mean(dane$centreDistance))/sd(dane$centreDistance))
# mean((dane$buildingAge-mean(dane$buildingAge))/sd(dane$buildingAge))
# mean((dane$schoolDistance-mean(dane$schoolDistance))/sd(dane$schoolDistance))
# mean((dane$clinicDistance-mean(dane$clinicDistance))/sd(dane$clinicDistance))
# mean((dane$postOfficeDistance-mean(dane$postOfficeDistance))/sd(dane$postOfficeDistance))
# mean((dane$kindergartenDistance-mean(dane$kindergartenDistance))/sd(dane$kindergartenDistance))
# mean((dane$restaurantDistance-mean(dane$restaurantDistance))/sd(dane$restaurantDistance))
# mean((dane$collegeDistance-mean(dane$collegeDistance))/sd(dane$collegeDistance))
# mean((dane$pharmacyDistance-mean(dane$pharmacyDistance))/sd(dane$pharmacyDistance))
# mean((dane$poiCount-mean(dane$poiCount))/sd(dane$poiCount))
```


```{r tab_zscore, results='asis', eval=TRUE, echo=FALSE}

wyniki <- data.frame(
  Zmienna = c("buildYear", "price", "squareMeters", "pricePerSquareMeter", "rooms",
              "floor", "floorCount", "centreDistance", "buildingAge", "schoolDistance",
              "clinicDistance", "postOfficeDistance", "kindergartenDistance", 
              "restaurantDistance", "collegeDistance", "pharmacyDistance", "poiCount"),
  Wartosc = c("1.321569e-15", "9.155718e-17", "3.0552e-17", "-5.888089e-17", "-1.961117e-16",
              "-3.274304e-17", "-9.234339e-17", "-1.348539e-16", "8.221441e-17", "1.247826e-17",
             " 2.77439e-17", "9.446714e-17", "-4.220434e-17", "5.62074e-17", "-2.656712e-17",
              "-1.519166e-17", "-2.97876e-17")
)
knitr::kable(wyniki, caption = "Wyniki Z-Score")
```


Standaryzacja przy użyciu z-score umożliwia identyfikację wartości odstających. Wartości, które są znacznie większe lub mniejsze niż 3 odchylenia standardowe, mogą być traktowane jako odstające. Zastosowanie z-score zapewniło, że wszystkie analizowane zmienne są zbalansowane wokół średniej, co stanowi podstawę do dalszych, bardziej szczegółowych analiz. Większość wartości w danych jest symetrycznie rozłożona wokół średniej i nie dominuje żaden zbiór ekstremalnych wartości.




```{r dodanie_nowych_danych, eval=TRUE, echo=FALSE}
# Wczytanie granic admistracyjnych województw
gml_file <- "ms_A01_Granice_wojewodztw.gml"

# Wczytanie danych przestrzennych
wojewodztwa <- st_read(gml_file)

# Tworzenie punktów z danych (longitude i latitude)
punkty <- st_as_sf(dane, coords = c("longitude", "latitude"), crs = 4326)

# Dopasowanie układu współrzędnych punktów do układu pliku GML
punkty <- st_transform(punkty, st_crs(wojewodztwa))

# Dopasowanie punktów do granic województw
dane_with_region <- st_join(punkty, wojewodztwa)

# Dodanie kolumny 'wojewodztwo' na podstawie JPT_NAZWA_
dane$wojewodztwo <- dane_with_region$JPT_NAZWA_

# Sprawdzenie wyników
#head(dane$wojewodztwo)

# Obliczenie średniej ceny za metr kwadratowy na województwo
srednie_ceny_m2 <- dane %>%
  group_by(wojewodztwo) %>%
  summarise(srednia_cena_m2 = mean(pricePerSquareMeter, na.rm = TRUE))

# Połączenie danych o cenach z granicami województw
wojewodztwa <- wojewodztwa %>%
  left_join(srednie_ceny_m2, by = c("JPT_NAZWA_" = "wojewodztwo"))

# Obliczenie centroidów województw dla etykiet
wojewodztwa_centroidy <- wojewodztwa %>%
  st_centroid() %>%
  mutate(label = JPT_NAZWA_)
```

```{r wykres_choropleth}
# Tworzenie mapy choropleth
ggplot(data = wojewodztwa) +
  geom_sf(aes(fill = srednia_cena_m2), color = "black", size = 0.2) +
  scale_fill_gradient(name = "Śr. cena za m² (PLN)", 
                      low = "white", high = "red", na.value = "gray",
                      labels = label_number(big.mark = " ", decimal.mark = ",")) +
  geom_sf_text(data = wojewodztwa_centroidy, aes(label = label), size = 3, color = "black") +
  theme_minimal() +
  labs(title = "Średnia cena za m² w Polsce według województw",
       caption = "Źródło: https://www.geoportal.gov.pl/") +
  theme(legend.position = "right")
```
