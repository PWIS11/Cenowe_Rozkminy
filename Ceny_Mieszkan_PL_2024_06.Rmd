---
title: "Analiza cen mieszkań w Polsce"
date: "`r Sys.Date()`"
author: "Piotr Wiśniewski - lider zespołu, Izabela Reszka, Klaudia Woźniak"
output:
  html_document:
    theme: cerulean
    highlight: tango
    highlight_color: "goldenrod"
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
## Global options
knitr::opts_chunk$set(cache = TRUE)
# Instalacja Pakietów
if (!requireNamespace("httr", quietly = TRUE)) install.packages("httr")
if (!requireNamespace("jsonlite", quietly = TRUE)) install.packages("jsonlite")
if (!requireNamespace("tidygeocoder", quietly = TRUE)) install.packages("tidygeocoder")
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
if (!requireNamespace("sf", quietly = TRUE)) install.packages("sf")
if (!requireNamespace("ggplot2", quietly = TRUE)) install.packages("ggplot2")
if (!requireNamespace("scales", quietly = TRUE)) install.packages("scales")
if (!requireNamespace("tidyverse", quietly = TRUE)) install.packages("tidyverse")
if (!requireNamespace("naniar", quietly = TRUE)) install.packages("naniar")
if (!requireNamespace("VIM", quietly = TRUE)) install.packages("VIM")
if (!requireNamespace("outliers", quietly = TRUE)) install.packages("outliers")
if (!requireNamespace("caret", quietly = TRUE)) install.packages("caret")
if (!requireNamespace("mice", quietly = TRUE)) install.packages("mice")
if (!requireNamespace("gridExtra", quietly = TRUE)) install.packages("gridExtra")
if (!requireNamespace("dlookr", quietly = TRUE)) install.packages("dlookr")
if (!requireNamespace("validate", quietly = TRUE)) install.packages("validate")
if (!requireNamespace("plotly", quietly = TRUE)) install.packages("plotly")
```

```{r libraries, include=FALSE}
library(httr)
library(jsonlite)
library(tidygeocoder)
library(dplyr)
library(sf)
library(ggplot2)
library(scales)
library(tidyverse)
library(naniar)
library(VIM)
library(outliers)
library(caret)
library(mice)
library(gridExtra)
library(dlookr)
library(validate)
library(plotly)
```

# **Cel projektu**
<p style="text-align: justify;">
Celem naszego projektu jest analiza cen mieszkań w największych miastach Polski, uwzględniając różnorodne czynniki, które mogą wpływać na wartość nieruchomości. Wykorzystamy metody analizy danych, aby odpowiedzieć na kluczowe pytania, takie jak:
</p>

-   *Od czego zależy cena mieszkań?*

-   *Jakie różnice w cenach występują pomiędzy miastami?*

-   *Czy odległość od centrum lub interesujących miejsc (POI) ma znaczenie dla wartości nieruchomości?*

-   *Które cechy mieszkań (np. liczba pokoi, stan, udogodnienia) są najbardziej cenione?*

## **Analizy w projekcie**

Planujemy zastosowanie narzędzi analizy danych oraz wizualizacji, aby lepiej zrozumieć rynek nieruchomości w Polsce. Nasze analizy obejmą:

-   Badanie zależności między cechami mieszkań (takimi jak lokalizacja, powierzchnia, liczba pokoi) a ich ceną.

-   Porównanie cen nieruchomości pomiędzy największymi polskimi miastami, w celu wykazania kluczowych różnic regionalnych.

-   Modelowanie predykcyjne, które pozwoli oszacować cenę mieszkań na podstawie wybranych zmiennych, takich jak odległość od centrum czy stan mieszkania.

-   Wykorzystanie interaktywnych wizualizacji, takich jak mapy i wykresy, aby przedstawić wyniki w przystępny sposób.

### **Hipotezy i oczekiwane wyniki**

1.  **Odległość od centrum miasta:** Zakładamy, że im bliżej centrum, tym wyższa cena mieszkań, choć siła tego wpływu może różnić się w zależności od miasta.

2.  **Cechy nieruchomości:** Udogodnienia takie jak balkon, winda czy miejsce parkingowe znacząco podnoszą wartość mieszkań, zwłaszcza w dużych miastach.

3.  **Różnice regionalne:** Miasta o wyższym poziomie urbanizacji i rozwiniętej infrastrukturze (np. Warszawa, Kraków, Wrocław) mają wyższe ceny mieszkań w porównaniu do mniejszych miejscowości.

4.  **Rok budowy:** Starsze mieszkania, wymagające remontu, są z reguły tańsze, chyba że znajdują się w prestiżowych lokalizacjach.

Podsumowując, oczekujemy, że nasze analizy wskażą najważniejsze czynniki wpływające na ceny mieszkań oraz umożliwią stworzenie użytecznych modeli predykcyjnych, które mogą wspierać decyzje zakupowe lub inwestycyjne.

## **Opis danych**
<p style="text-align: justify;">
Zbiór danych pochodzi z ofert sprzedaży i wynajmu mieszkań z 15 największych polskich miast, zgromadzonych w czerwcu 2024 roku. Dane te obejmują szerokie spektrum cech nieruchomości oraz dodatkowe informacje z Open Street Map, które pozwalają uwzględnić kontekst sąsiedztwa mieszkań.
</p>

**Miasta w zbiorze danych:** Warszawa, Łódź, Kraków, Wrocław, Poznań, Gdańsk, Szczecin, Bydgoszcz, Lublin, Katowice, Białystok, Częstochowa.

**Główne pola w zbiorze danych:**

-   ***Lokalizacja i charakterystyka nieruchomości:***

    -   Miasto, typ budynku, wielkość w metrach kwadratowych, liczba pokoi, piętro, rok budowy.

-   ***Informacje kontekstowe:***

    -   Odległość od centrum miasta, liczba interesujących punktów w promieniu 500 metrów (np. szkoły, apteki, restauracje) oraz odległość do najbliższego punktu.

-   ***Cechy nieruchomości:***

    -   Stan mieszkania, rodzaj własności, obecność udogodnień (np. winda, balkon, miejsce parkingowe, ochrona).

-   ***Cena ofertowa:***

    -   Cena sprzedaży lub miesięczny czynsz.

## **Dane dodatkowe**
<p style="text-align: justify;">
W celu wykonania bardziej szczegółowej analizy zdecydowaliśmy się wzbogacić nasz zbiór o **granice administracyjne województw**. Dane te zostały pobrane z pliku **`ms_A01_Granice_wojewodztw`** i umożliwiły przypisanie każdego miasta do odpowiedniego województwa.
</p>
### **Cel dodania danych:**

-   **Przypisanie lokalizacji mieszkań do województw**,\
-   **Przeprowadzenie analiz regionalnych**, aby lepiej zrozumieć różnice w cenach i cechach mieszkań w różnych częściach Polski.

Dzięki temu możliwe jest nie tylko szczegółowe badanie rynku nieruchomości na poziomie miast, ale także **porównanie wyników w kontekście regionalnym**.

## **Znaczenie projektu**
<p style="text-align: justify;">
Rynek nieruchomości jest dynamiczny i podlega wpływowi wielu czynników, takich jak lokalizacja, liczba pokoi, dostępność udogodnień czy bliskość kluczowych miejsc. Analiza tych danych pozwoli lepiej zrozumieć mechanizmy kształtowania się cen mieszkań oraz stworzyć narzędzia wspomagające decyzje zakupowe i inwestycyjne.
</p>
```{r wstepna_obrobka_danych, echo=FALSE}
dane <- read.csv("apartments_pl_2024_06.csv", sep = ",", header = TRUE)

# Zmiana id na liczby rosnące, zaczynające się od cyfry 1
dane$id <- 1:nrow(dane)

# Zamiana pustych ciągów na NA
dane[dane == ""] <- NA
```

# **Data validation**


```{r weryfikacja_typów_danych, echo=FALSE, results='asis', eval=TRUE}
# Sprawdzenie struktury danych i sptawdzenie pierwszych kilku wierszy danych
# str(dane)
# head(dane)

# Sprawdzenie i weryfikacja typów danych i liczby unikalnych wartości w każdej kolumnie
data_types <- sapply(dane, class) 
unique_values <- sapply(dane, function(x) length(unique(x)))

data_types <- data.frame(
  Typ = data_types,              
  Liczba_unikalnych = unique_values
)

knitr::kable(data_types, caption = "Typy Danych oraz ich ilość")
```


```{r weryfikacja_typów_danych2, echo=FALSE, results='asis', eval=TRUE}
# Podsumowanie ile kolumn jest każdego typu
liczba_numeric <- sum(data_types == "numeric")
liczba_character <- sum(data_types == "character")
liczba_factor <- sum(data_types == "factor")
liczba_integer <- sum(data_types == "integer")
liczba_logical <- sum(data_types == "logical")

data_types <- data.frame(
  Typ = c("Numeric", "Character", "Factor", "Integer", "Logical"),
  Liczba_kolumn = c(liczba_numeric, liczba_character, liczba_factor, liczba_integer, liczba_logical)
)

knitr::kable(data_types, caption = "Typy Danych")

```
<p style="text-align: justify;">
Zbiór danych składa się z 28 kolumn, które charakteryzują się następującymi typami: 18 zmiennych numerycznych (typ numeric), 6 zmiennych tekstowych (typ character), 3 zmiennymi kategorycznymi (typ factor), 2 zmiennymi całkowitymi (typ integer) oraz brakiem zmiennych logicznych. 
</p>

<p style="text-align: justify;">
Zmienne numeryczne, takie jak squareMeters, price czy centreDistance, mają dużą liczbę unikalnych wartości, co sugeruje, że są to dane ciągłe, które będą odpowiednie do analizy regresyjnej. Zmienne kategoryczne, takie jak type, ownership czy buildingMaterial, mogą być traktowane jako zmienne typu factor i wykorzystane w analizach klasyfikacyjnych. Z kolei kolumny z typem integer, jak np. price, również mogą być używane w analizach numerycznych.
</p>

<p style="text-align: justify;">
Dzięki tej weryfikacji możemy odpowiednio przygotować dane do dalszej analizy i modelowania. Zmienne numeryczne będą wykorzystywane w analizach regresyjnych, zmienne typu factor w klasyfikacyjnych, a zmienne character mogą wymagać kodowania na typ factor, aby mogły być wykorzystane w dalszej analizie. Na podstawie tej analizy możemy przejść do przygotowania danych do modelowania, dobierając odpowiednie metody przetwarzania, takie jak kodowanie zmiennych kategorycznych, normalizację zmiennych numerycznych czy tworzenie nowych zmiennych, w zależności od typu danych i celu analizy.
</p>

<p style="text-align: justify;">
Walidacja danych to proces, którego celem jest weryfikacja, czy dane spełniają określone kryteria, zapewniając ich poprawność, spójność oraz integralność. Jego zadaniem jest upewnienie się, że dane są zgodne z wymaganiami jakościowymi i formatowymi, które są kluczowe dla dalszego przetwarzania i analizy. W ramach tego procesu zdefiniowaliśmy i zastosowaliśmy reguły walidacyjne, mające na celu analizę spójności logicznej badanych zmiennych. Przyjęte zasady pozwalają na dokładną weryfikację poprawności danych, zapewniając ich zgodność z określonymi kryteriami logicznymi.
</p>

 1) Piętro (Floor) nie może być większe niż liczba kondygnacji (Floor Count).
 2) Rok budowy (Build Year) nie może być późniejszy niż bieżący rok (2024).
 3) Rok budowy musi być późniejszy niż 1600.
 4) Piętro (Floor) i liczba kondygnacji (Floor Count) muszą być większe lub równe 0.
 5) Liczba pokoi (Rooms) musi być większa niż 0 i nie może przekraczać 15.
 6) Jeżeli liczba kondygnacji (Floor Count) wynosi 0, to nie powinno być w takim budynku windy (Has Elevator).
 
```{r walidacja_wstępna_danych, echo=FALSE,out.width="83%", fig.width=14, fig.height=9}

# Definiowanie reguł walidacyjnych

rules <- validator(
  "Floor>Floor Count" = floor <= floorCount,                                            # Piętro nie większe niż liczba kondygnacji
  "BuildYear<= 2024" = buildYear <= 2024,                                               # Rok budowy nie większy niż rok bieżący
  "BuildYear > 1600" = buildYear > 1600,                                                 # Rok budowy późniejszy niż 1600
  "Floor>= 0" = floor >= 0,                                                              # Piętro nie może być ujemne
  "FloorCount >= 0" = floorCount >= 0,                                                   # Liczba kondygnacji nie może być ujemna
  "Rooms> 0" = rooms > 0,                                                                # Liczba pokoi większa niż 0
  "Rooms<= 15" = rooms <= 15,                                                            # Liczba pokoi nie większa niż 15
  "Elevator in a building with 0 floors" = !(floorCount == 0 & hasElevator == "yes")      # Sprawdzenie, czy budynek z 0 kondygnacjami ma windę

)


out <- confront(dane, rules)

rules_names <- c("Floor > Floor Count", "Build Year <= 2024", "Build Year > 1600", 
                 "Floor >= 0", "Floor Count >= 0", "Rooms > 0", "Rooms <= 15", "Elevator in a building with 0 floors")

expressions <- c("Floor <= Floor Count", "Build Year <= 2024", "Build Year > 1600", 
                 "Floor >= 0", "Floor Count >= 0", "Rooms > 0", "Rooms <= 15", "!(floorCount == 0 & hasElevator == 'yes')")

results <- lapply(c("Floor > Floor Count", "Build Year <= 2024", "Build Year > 1600", 
                    "Floor >= 0", "Floor Count >= 0", "Rooms > 0", "Rooms <= 15", "Elevator in a building with 0 floors"), 
                  function(x) out$`._value`[[x]])


results_logical <- lapply(results, function(x) x == 1)
passes <- sapply(results_logical, sum)
nNA <- sapply(results_logical, function(x) sum(!x))  

# Przygotowanie wyników walidacji
validation_results <- data.frame(
  rule = rules_names,
  examined_observations = rep(21501, 8),
  observations_passing_rule = passes,
  observations_failing_rule = nNA,
  rule_expression = expressions
)

# Wykres wyników walidacji z podziałem na reguły
plot(out)

```

W wyniku przeprowadzonej walidacji w zbiorze danych zauważono znaczną obecność wartości NA (brakujących danych), które pojawiły się kolumnach. W dalszej części analizy planuje się ich imputację, przy czym wartości te zostaną zastąpione: medianą dla zmiennych o charakterze numerycznym, a modą dla zmiennych kategorycznych. 


# **Data wrangling**

<p style="text-align: justify;">
Proces **data wrangling** umożliwia przekształcenie surowego zbioru danych w uporządkowaną i spójną strukturę gotową do dalszych badań. W ramach tego etapu skoncentrowaliśmy się na dwóch głównych aspektach: analizie wartości brakujących oraz obserwacji odstających.  
</p>

W tej części projektu podjęliśmy działania mające na celu:
- zrozumienie i klasyfikację braków danych (MCAR, MAR, MNAR), 
- wybór odpowiednich strategii imputacji brakujących wartości,
- wykrycie i obsługę obserwacji odstających, które mogą zaburzać statystyczne wnioski.

<p style="text-align: justify;">
Dzięki zastosowaniu odpowiednich metod wizualizacji (np. wykresów pudełkowych i macierzy braków) oraz technik statystycznych (np. Z-score) możliwe było zarówno dokładne zrozumienie problemów związanych z danymi, jak i zaplanowanie działań korygujących. Tak przygotowany zbiór danych stanowi podstawę do przeprowadzenia dalszych analiz i modelowania.
</p>

<p style="text-align: justify;">
W kolejnych sekcjach przedstawimy szczegółowe kroki przeprowadzone w ramach tego etapu, w tym wyniki analizy braków danych oraz identyfikacji wartości odstających, a także opis zastosowanych metod ich obsługi.
</p>

## **Obserwacje brakujące**

<p style="text-align: justify;">
Do analizy brakujących danych zdecydowaliśmy się wykorzystać zarówno wizualizacje które pozwolą zrozumieć skalę oraz potencjalne przyczyny braków w zbiorze danych. Wizualizacje, takie jak **wykresy słupkowe** prezentujące procent brakujących wartości w poszczególnych zmiennych oraz graficzne przedstawienie wzorców braków, umożliwiają szybkie zidentyfikowanie kolumn najbardziej dotkniętych problemem brakujących danych. Dodatkowo zastosowanie **macierzy braków** pozwala na analizę współwystępowania braków pomiędzy zmiennymi, co może wskazać na możliwe zależności w danych.
</p>

Na podstawie klasyfikacji braków danych (MCAR, MAR, MNAR) możemy lepiej zrozumieć przyczyny ich występowania.

-   **MCAR (Missing Completely At Random)**: Braki w kolumnach takich jak hasElevator i collegeDistance są losowe i wynikają z technicznych pominięć w zbieraniu danych.

-   **MAR (Missing At Random)**: Braki w kolumnach condition, buildingMaterial, oraz floor wynikają z powiązań między zmiennymi, np. type i floorCount.

-   **MNAR (Missing Not At Random)**: Braki w type mogą wynikać z mechanizmu niechęci podawania wartości (np. dla mieszkań luksusowych).

Dzięki tym wstępnym analizom możliwe jest odpowiednie dobranie metod imputacji (np. medianą, modą lub bardziej zaawansowanymi metodami), a także ewentualne usunięcie zmiennych, w których braki są zbyt liczne i niemożliwe do uzupełnienia bez znaczącej utraty jakości danych.

```{r obserwacje_brakujace_wykresy, echo=FALSE, comment=FALSE}
missing_summary <- miss_var_summary(dane)

ggplot(missing_summary, aes(x = reorder(variable, -pct_miss), y = pct_miss)) +
  geom_bar(stat = "identity", fill = "plum2") +
  coord_flip() +
  labs(title = "Procent brakujących wartości w kolumnach",
       x = "Zmienne",
       y = "Procent braków (%)") +
  theme_minimal()
```

```{r obserwacje_brakujace_wykresy_2, echo=FALSE}
suppressMessages({
  vismiss <- vis_miss(dane) +
    scale_fill_manual(values = c("lightyellow", "orchid3"),
                      name = "Status danych",
                      labels = c("Dane obecne", "Braki danych")) +
    labs(
      title = "Braki danych w zbiorze",
      x = "Zmienne",
      y = "Obserwacje"
    ) +
    theme_minimal(base_size = 10) + 
    theme(
      plot.title = element_text(hjust = 0.5),
      axis.text.x = element_text(angle = 45, hjust = 0.2)
    )
  
  print(vismiss)
})
```

Analiza brakujących danych wskazuje, że kolumny w zbiorze można podzielić na kilka grup pod względem liczby braków:

-   **Bardzo duża liczba braków:** condition (74.0%) i buildingMaterial (40.9%). Ze względu na ich wysoką niekompletność zdecydowaliśmy się usunąć kolumnę condition, a dla buildingMaterial zastosujemy imputację najczęstszą wartością.

-   **Umiarkowana liczba braków:** type (20.5%), floor (16.6%), buildYear (15.7%). Uzupełnimy brakujące wartości odpowiednio metodą najczęstszej wartości dla zmiennych kategorycznych (type) oraz medianą dla zmiennych liczbowych (floor, buildYear).

-   **Niewielka liczba braków:** Kolumny takie jak hasElevator (4.46%) czy collegeDistance (2.72%) zostaną uzupełnione odpowiednio modą i medianą.

-   **Bardzo mała liczba braków:** Pozostałe kolumny z mniej niż 1% braków zostaną imputowane prostymi metodami (medianą lub najczęstszą wartością).

-   **Kolumny bez braków:** Pozostałe zmienne, takie jak price, squareMeters czy rooms, są kompletne i nie wymagają dodatkowych działań.

```{r wzorce_brakow, echo=FALSE, warning=FALSE, message=FALSE}
# Zwiększenie rozmiaru wykresu
options(repr.plot.width = 14, repr.plot.height = 10)

# Tworzenie wykresu z jeszcze mniejszymi czcionkami
aggr(dane, 
     col = c("lightyellow", "orchid3"), 
     numbers = TRUE, 
     sortVars = TRUE,
     labels = names(dane), 
     cex.axis = 0.4, # Zmniejszenie czcionki osi
     gap = 1.5,      # Zmniejszenie odstępów między elementami
     ylab = c("Procent braków", "Wzorce braków"))
```

#### usunałbym w tym miejscu ten message który generuje R w postaci tabeli. wykres wzorca braków umieściłbym zaraz pod vismiss, a pod nimi dał ten opis o analizie

### Imputacja medianą oraz modą


```{r Zastąpienie_braków_medianą_i_najczęstszą_wartością, echo = FALSE}

#### Iza - czy tutaj chcemy dać jakieś podsumowanie, ilu zmian dokonano per kolumna?

################################################################################

dane$floor<-imputate_na(dane, floor, method = "median")
dane$buildYear<-imputate_na(dane, buildYear, method = "median")
dane$collegeDistance<-imputate_na(dane, collegeDistance, method = "median")
dane$schoolDistance<-imputate_na(dane, schoolDistance, method = "median")
dane$pharmacyDistance<-imputate_na(dane, pharmacyDistance, method = "median")
dane$kindergartenDistance<-imputate_na(dane, kindergartenDistance, method = "median")
dane$clinicDistance<-imputate_na(dane, clinicDistance, method = "median")
dane$postOfficeDistance<-imputate_na(dane, postOfficeDistance, method = "median")
dane$restaurantDistance<-imputate_na(dane, restaurantDistance, method = "median")
dane$floorCount<-imputate_na(dane, floorCount, method = "median")
################################################################################

#table(na.omit(dane$type)) SPRAWDZENIE CZĘSTOSCI WYSTĘPOWANIA
#table(na.omit(dane$buildingMaterial)) SPRAWDZENIE CZĘSTOSCI WYSTĘPOWANIA
#table(na.omit(dane$hasElevator))

dane$type[is.na(dane$type)] <- "blockOfFlats"
dane$buildingMaterial[is.na(dane$buildingMaterial)] <- "brick"
dane$hasElevator[is.na(dane$hasElevator)] <- "yes"

dane$type <- factor(dane$type)
dane$buildingMaterial <- factor(dane$buildingMaterial)
dane$hasElevator <- factor(dane$hasElevator)

################################################################################
dane$condition <- NA
dane <- subset(dane, select = -condition)
################################################################################
```


```{r Dodanie_dodatkowych_kolumn_cena_za_metr_wiek_mieszkania,echo = FALSE}

# Dodanie kolumny z ceną za metr kwadratowy
dane$pricePerSquareMeter <- dane$price / dane$squareMeters

# Dodanie kolumny z wiekiem mieszkania
currentYear <- format(Sys.Date(), "%Y")
dane$buildingAge <- ifelse(is.na(dane$buildYear), NA, as.numeric(currentYear) - dane$buildYear)
```

## **Obserwacje odstające**
<p style="text-align: justify;">
Do analizy obserwacji odstających decydowaliśmy się użyć **wykresów pudełkowych**, ponieważ są one prostym i skutecznym narzędziem wizualizacyjnym, które pozwala szybko zidentyfikować wartości odstające. Dzięki nim poznamy wartości minimalne, maksymalne, mediane, kwartyle oraz ewentualne wartości wykraczające poza tzw. *wąsy*, czyli zakres między pierwszym a trzecim kwartylem powiększony. Każda z analizowanych zmiennych została przedstawiona na osobnym wykresie pudełkowym, co pozwala dokładnie przyjrzeć się rozkładowi poszczególnych cech, takich jak powierzchnia mieszkania, cena, cena za metr kwadratowy czy odległości od różnych punktów użyteczności publicznej. Dzięki temu można szybko zidentyfikować zmienne, które mogą zawierać nietypowe wartości i potencjalnie wpłynąć na dalsze analizy lub modelowanie danych.
</p>
<p style="text-align: justify;">
Dodatkowo, aby potwierdzić statystycznie obecność obserwacji odstających zastosowaliśmy metodę Z-score oraz zbadaliśmy czy rozkład danych jest zbliżony do rozkładu normalnego.
</p>
Metoda **Z-score**, polega na identyfikowaniu obserwacji odstających na podstawie odchylenia standardowego od średniej. Wyraża się wzorem: $$
         Z = \frac{x - \bar{x}}{\sigma}
         $$ $x$: wartość obserwacji\
    $\overline{x}$: średnia dla danej zmiennej\
    $\sigma$: odchylenie standardowe.

**Skośność** jest statystyką umożliwiającą porównanie rozkładu analizowanej zmiennej z hipotetycznym rozkładem normalnym. Wskazuje na rozbieżności pomiędzy wartością średnią, a centrum danego rozkładu. Wyraża się wzorem:

$$\tilde{\mu}_3 = \frac{\sum_{i}^{N} (X_i - \bar{X})^3}{(N - 1) \cdot \sigma^3}$$

-   $\tilde{\mu}_3$ = skośność
-   $N$ = liczba zmiennych w rozkładzie
-   $X_i$ = losowa zmienna
-   $\bar{X}$ = średnia rozkładu
-   $\sigma$ = odchylenie standardowe.

Interpretacja jest następująca:

-   Rozkład prawoskośny -- skośność jest dodatnia, prawe ramię rozkładu jest wydłużone, wyniki poniżej średniej są przeważające w badanej próbce.

-   Rozkład symetryczny -- skośność wynosi 0, ogony rozkładu są identyczne w obu kierunkach. Jeśli znormalizowana kurtoza wynosi 0, rozkład jest zbliżony do rozkładu normalnego.

-   Rozkład lewoskośny -- skośność jest ujemna, lewe ramię rozkładu jest wydłużone, większość obserwacji w próbie ma wartości powyżej średniej.

### Wykresy pudełkowe

```{r zamiana_na_numeryczne, echo=FALSE}
dane$buildingAge <- as.numeric(dane$buildingAge)
dane$latitude <- as.numeric(dane$latitude)
dane$longitude <- as.numeric(dane$longitude)
dane$centreDistance <- as.numeric(dane$centreDistance)
dane$schoolDistance <- as.numeric(dane$schoolDistance)
dane$clinicDistance <- as.numeric(dane$clinicDistance)
dane$postOfficeDistance <- as.numeric(dane$postOfficeDistance)
dane$kindergartenDistance <- as.numeric(dane$kindergartenDistance)
dane$collegeDistance <- as.numeric(dane$collegeDistance)
dane$restaurantDistance <- as.numeric(dane$restaurantDistance)
dane$pharmacyDistance <- as.numeric(dane$pharmacyDistance)
dane$floorCount <- as.numeric(dane$floorCount)
```

```{r boxplot_odst, fig.height=10, fig.width=10, echo=FALSE, fig.show='hold'}
# Renderowanie pierwszej strony (9 wykresów)
par(mfrow = c(3, 3))  # Układ 3x3
boxplot(dane$squareMeters, main = "Square Meters", col = "skyblue")
boxplot(dane$price, main = "Price", col = "plum")
boxplot(dane$pricePerSquareMeter, main = "PricePerSquareMeter", col = "peachpuff")
boxplot(dane$rooms, main = "Rooms", col = "palegreen2")
boxplot(dane$floor, main = "Floors", col = "powderblue")
boxplot(dane$floorCount, main = "FloorCount", col = "thistle3")
boxplot(dane$buildingAge, main = "BuildingAge", col = "salmon")
boxplot(dane$centreDistance, main = "CentreDistance", col = "pink4")
boxplot(dane$schoolDistance, main = "SchoolDistance", col = "pink")
```


```{r boxplot_odst2, fig.height=7, fig.width=10, echo=FALSE, fig.show='hold'}
# Resetowanie układu
par(mfrow = c(2, 3))  # Układ 2x3 dla 6 miejsc

# Renderowanie drugiej strony (5 wykresów + puste miejsce)
boxplot(dane$clinicDistance, main = "ClinicDistance", col = "orange")
boxplot(dane$postOfficeDistance, main = "PostOfficeDistance", col = "coral")
boxplot(dane$kindergartenDistance, main = "KindergardenDistance", col = "lavender")
boxplot(dane$restaurantDistance, main = "RestaurantDistance", col = "khaki")
boxplot(dane$collegeDistance, main = "CollegeDistance", col = "indianred")
boxplot(dane$pharmacyDistance, main = "PharmacyDistance", col = "lavenderblush2")
```



#### **Interpretacja wyników wykresów pudełkowych**

Przeprowadzona analiza wykresów pudełkowych pozwoliła na dokładne przyjrzenie się rozkładom badanych cech mieszkań, takich jak powierzchnia, cena, liczba pokoi oraz odległości do punktów użyteczności publicznej. Wykresy te umożliwiły identyfikację wartości **typowych** (mediana, kwartyle) oraz **wartości odstających**, które wykraczają poza zakres wyznaczony przez *wąsy*.\

Wartości odstające są szczególnie istotne, ponieważ mogą wskazywać na specyficzne obserwacje, takie jak:

-   **Nieruchomości luksusowe** lub o nietypowej wielkości i cenie,\
-   **Mieszkania położone w trudno dostępnych lokalizacjach**,\
-   **Nieruchomości w starszych budynkach** lub obszarach o słabo rozwiniętej infrastrukturze.

Poniżej przedstawiono szczegółową interpretację wyników dla każdej z analizowanych zmiennych.



**Square Meters (Powierzchnia mieszkań):**\
- Mediana powierzchni wynosi około **50-60 m²**.\
- Większość mieszkań mieści się w zakresie **40-80 m²**.\
- **Wartości odstające** powyżej **100 m²** wskazują na większe apartamenty lub luksusowe nieruchomości.

**Price (Cena mieszkań):**\
- Mediana ceny mieszkań wynosi około **750 tys. zł**.\
- Typowe wartości mieszczą się w przedziale **500 tys. – 1 mln zł**.\
- Liczne **wartości odstające** powyżej **2,5 mln zł** sugerują obecność luksusowych nieruchomości w analizowanym zbiorze.

**PricePerSquareMeter (Cena za m²):**\
- Mediana wynosi około **15 000 zł/m²**, a większość wartości mieści się w zakresie **10 000 – 20 000 zł/m²**.\
- **Wartości odstające** przekraczające **30 000 zł/m²** mogą wynikać z mieszkań położonych w bardzo prestiżowych lokalizacjach.

**Rooms (Liczba pokoi):**\
- Typowe mieszkania mają **2-3 pokoje**, co potwierdza mediana.\
- **Wartości odstające** (4-6 pokoi) mogą wskazywać na większe mieszkania lub apartamenty rodzinne.

**Floors (Piętro):**\
- Mediana piętra to około **2**.\
- Większość mieszkań znajduje się na **1-5 piętrze**.\
- **Wartości odstające** powyżej **15 piętra** sugerują obecność mieszkań w wieżowcach.

**FloorCount (Liczba pięter w budynku):**\
- Typowe budynki mają **4-6 pięter**.\
- **Wartości odstające** powyżej **15 pięter** wskazują na obecność wysokich budynków mieszkalnych.

**BuildingAge (Wiek budynku):**\
- Mediana wieku budynków wynosi około **50 lat**.\
- Budynki mające więcej niż **100 lat** to **wartości odstające**, co sugeruje obecność starszych, często zabytkowych nieruchomości.

**CentreDistance (Odległość od centrum):**\
- Typowa odległość to **2-8 km**.\
- **Wartości odstające** powyżej **15 km** wskazują na nieruchomości położone na przedmieściach lub w odległych lokalizacjach.

**SchoolDistance (Odległość od szkoły):**\
- Większość szkół znajduje się w odległości **do 1 km**.\
- **Wartości odstające** powyżej **4 km** mogą świadczyć o gorszej dostępności edukacji w analizowanych lokalizacjach.

**ClinicDistance (Odległość od kliniki):**\
- Kliniki są najczęściej położone **do 1 km** od mieszkań.\
- **Wartości odstające** powyżej **3 km** wskazują na obszary o niższym dostępie do opieki zdrowotnej.

**PostOfficeDistance (Odległość od poczty):**\
- Typowa odległość wynosi **0-1 km**.\
- **Wartości odstające** powyżej **4 km** mogą wynikać z mniej zurbanizowanych obszarów.

**KindergardenDistance (Odległość od przedszkola):**\
- Przedszkola znajdują się głównie **do 1 km** od mieszkań.\
- **Wartości odstające** powyżej **3 km** sugerują problemy z dostępem do usług dla rodzin z dziećmi.

**RestaurantDistance (Odległość od restauracji):**\
- Restauracje znajdują się typowo **do 1 km** od mieszkań.\
- **Wartości odstające** powyżej **5 km** wskazują na peryferyjne lokalizacje z ograniczoną ofertą gastronomiczną.

**CollegeDistance (Odległość od uczelni):**\
- Typowa odległość wynosi **1-2 km**.\
- **Wartości odstające** do **5 km** sugerują lokalizacje mniej centralne pod względem infrastruktury edukacyjnej.

**PharmacyDistance (Odległość od apteki):**\
- Apteki znajdują się zazwyczaj **do 1 km** od mieszkań.\
- **Wartości odstające** powyżej **4 km** wskazują na obszary o ograniczonym dostępie do usług farmaceutycznych.


Analiza wykresów pudełkowych potwierdziła występowanie wartości odstających w każdej z badanych zmiennych. Są one szczególnie istotne, ponieważ mogą wskazywać na specyficzne segmenty rynku nieruchomości – luksusowe mieszkania, nieruchomości historyczne lub obszary z ograniczoną infrastrukturą.

Zidentyfikowane wartości odstające będą miały istotne znaczenie w dalszym modelowaniu oraz analizach statystycznych. Warto w kolejnych krokach rozważyć, czy te obserwacje powinny zostać zachowane jako istotne dla analizy, czy też przekształcone lub usunięte w zależności od kontekstu biznesowego i analitycznego.



### Skośność

<a id="centreDistancePlot"></a>
<a id="poiCountPlot"></a>
<a id="schoolDistancePlot"></a>
<a id="clinicDistancePlot"></a>
<a id="postOfficeDistancePlot"></a>
<a id="kindergartenDistancePlot"></a>
<a id="restaurantDistancePlot"></a>
<a id="collegeDistancePlot"></a>
<a id="pharmacyDistancePlot"></a>



```{r skosnosc, echo = FALSE, eval = TRUE, fig.height=6, fig.width=8}
par(mfrow = c(3, 3))  # Układ 3x3
hist(na.omit(dane$centreDistance), 
     probability = TRUE, 
     col = "plum1", 
     main = "Histogram - centreDistance", 
     xlab = "centreDistance")
curve(dnorm(x, mean = mean(na.omit(dane$centreDistance)), 
            sd = sd(na.omit(dane$centreDistance))), 
      col = "plum4", 
      lwd = 2, 
      add = TRUE)

# poiCount
hist(na.omit(dane$poiCount), 
     probability = TRUE, 
     col = "lightblue", 
     main = "Histogram - poiCount", 
     xlab = "poiCount")
curve(dnorm(x, mean = mean(na.omit(dane$poiCount)), 
            sd = sd(na.omit(dane$poiCount))), 
      col = "darkblue", 
      lwd = 2, 
      add = TRUE)

# schoolDistance
hist(na.omit(dane$schoolDistance), 
     probability = TRUE, 
     col = "lightgreen", 
     main = "Histogram - schoolDistance", 
     xlab = "schoolDistance")
curve(dnorm(x, mean = mean(na.omit(dane$schoolDistance)), 
            sd = sd(na.omit(dane$schoolDistance))), 
      col = "green4", 
      lwd = 2, 
      add = TRUE)

# clinicDistance
hist(na.omit(dane$clinicDistance), 
     probability = TRUE, 
     col = "lightpink", 
     main = "Histogram - clinicDistance", 
     xlab = "floorCount")
curve(dnorm(x, mean = mean(na.omit(dane$clinicDistance)), 
            sd = sd(na.omit(dane$clinicDistance))), 
      col = "violet", 
      lwd = 2, 
      add = TRUE)

# postOfficeDistance
hist(na.omit(dane$postOfficeDistance), 
     probability = TRUE, 
     col = "peachpuff", 
     main = "Histogram - postOfficeDistance", 
     xlab = "postOfficeDistance")
curve(dnorm(x, mean = mean(na.omit(dane$postOfficeDistance)), 
            sd = sd(na.omit(dane$postOfficeDistance))), 
      col = "orange1", 
      lwd = 2, 
      add = TRUE)

# kindergartenDistance
hist(na.omit(dane$kindergartenDistance), 
     probability = TRUE, 
     col = "lightyellow", 
     main = "Histogram - kindergartenDistance", 
     xlab = "kindergartenDistance")
curve(dnorm(x, mean = mean(na.omit(dane$kindergartenDistance)), 
            sd = sd(na.omit(dane$kindergartenDistance))), 
      col = "yellow2", 
      lwd = 2, 
      add = TRUE)
# restaurantDistance
hist(na.omit(dane$restaurantDistance), 
     probability = TRUE, 
     col = "grey", 
     main = "Histogram - restaurantDistance", 
     xlab = "restaurantDistance")
curve(dnorm(x, mean = mean(na.omit(dane$restaurantDistance)), 
            sd = sd(na.omit(dane$restaurantDistance))), 
      col = "grey1", 
      lwd = 2, 
      add = TRUE)
# collegeDistance
hist(na.omit(dane$collegeDistance), 
     probability = TRUE, 
     col = "red4", 
     main = "Histogram - collegeDistance", 
     xlab = "collegeDistance")
curve(dnorm(x, mean = mean(na.omit(dane$collegeDistance)), 
            sd = sd(na.omit(dane$collegeDistance))), 
      col = "tomato1", 
      lwd = 2, 
      add = TRUE)
# pharmacyDistance
hist(na.omit(dane$pharmacyDistance), 
     probability = TRUE, 
     col = "skyblue1", 
     main = "Histogram - pharmacyDistance", 
     xlab = "pharmacyDistance")
curve(dnorm(x, mean = mean(na.omit(dane$pharmacyDistance)), 
            sd = sd(na.omit(dane$pharmacyDistance))), 
      col = "dodgerblue3", 
      lwd = 2, 
      add = TRUE)
```
<a id="buildingAgePlot"></a>
<a id="squareMetersPlot"></a>
<a id="pricePlot"></a>
<a id="floorPlot"></a>
<a id="floorCountPlot"></a>
<a id="buildYearPlot"></a>

```{r skosnosc_hist2, echo = FALSE, eval = TRUE, fig.height=4, fig.width=8}
par(mfrow = c(2, 3))  # Układ 3x3
# postOfficeDistance
hist(na.omit(dane$buildingAge), 
     probability = TRUE, 
     col = "palegoldenrod", 
     main = "Histogram - buildingAge", 
     xlab = "buildingAge")
curve(dnorm(x, mean = mean(na.omit(dane$buildingAge)), 
            sd = sd(na.omit(dane$buildingAge))), 
      col = "palegreen3", 
      lwd = 2, 
      add = TRUE)

# squareMeters
hist(na.omit(dane$squareMeters), 
     probability = TRUE, 
     col = "deeppink", 
     main = "Histogram - squareMeters", 
     xlab = "squareMeters")
curve(dnorm(x, mean = mean(na.omit(dane$squareMeters)), 
            sd = sd(na.omit(dane$squareMeters))), 
      col = "deeppink4", 
      lwd = 2, 
      add = TRUE)

# price
hist(na.omit(dane$price), 
     probability = TRUE, 
     col = "antiquewhite", 
     main = "Histogram - price", 
     xlab = "price")
curve(dnorm(x, mean = mean(na.omit(dane$price)), 
            sd = sd(na.omit(dane$price))), 
      col = "indianred2", 
      lwd = 2, 
      add = TRUE)

# floor
hist(na.omit(dane$floor), 
     probability = TRUE, 
     col = "slategray2", 
     main = "Histogram - floor", 
     xlab = "floor")
curve(dnorm(x, mean = mean(na.omit(dane$floor)), 
            sd = sd(na.omit(dane$floor))), 
      col = "orchid", 
      lwd = 2, 
      add = TRUE)

# floorCount
hist(na.omit(dane$floorCount), 
     probability = TRUE, 
     col = "burlywood", 
     main = "Histogram - floorCount", 
     xlab = "floorCount")
curve(dnorm(x, mean = mean(na.omit(dane$floorCount)), 
            sd = sd(na.omit(dane$floorCount))), 
      col = "burlywood4", 
      lwd = 2, 
      add = TRUE)

# buildYear
hist(na.omit(dane$buildYear), 
     probability = TRUE, 
     col = "lightblue", 
     main = "Histogram - buildYear", 
     xlab = "buildYear")
curve(dnorm(x, mean = mean(na.omit(dane$buildYear)), 
            sd = sd(na.omit(dane$buildYear))), 
      col = "darkblue", 
      lwd = 2, 
      add = TRUE)
```


#### **Interpretacja wyników histogramów**
<p style="text-align: justify;">
Przeprowadzona analiza histogramów pozwoliła na dokładne przyjrzenie się rozkładom badanych cech mieszkań, takich jak powierzchnia, cena, liczba pięter oraz odległości do punktów użyteczności publicznej. Wykresy te umożliwiły identyfikację wartości **typowych** (dominanty, gęstość wartości) oraz **wartości odstających**, które znajdują się na krańcach rozkładów.
</p>

Linie rozkładu normalnego, nałożone na histogramy, stanowią dodatkowy punkt odniesienia do oceny kształtu rozkładów. Pozwalają one zidentyfikować:  

- **Odstępstwa od normalności**, takie jak skośność czy wielomodalność,  
- **Stopień zgodności rozkładów empirycznych z teoretycznym rozkładem normalnym**,  
- **Przesunięcia względem środka rozkładu** sugerujące koncentrację danych.  

---

**[centreDistance](#centreDistancePlot):**
- Rozkład jest **prawoskośny** z koncentracją wartości w zakresie **2-8 km**.  
- Linia rozkładu normalnego pokazuje, że rozkład empiryczny jest odchylony w prawo.  
- Wartości powyżej **10 km** stanowią odstępstwa, które wskazują na nieruchomości w peryferyjnych lokalizacjach, co jest nietypowe dla większości analizowanych danych.

**[poiCount](#poiCountPlot)** 
- Histogram pokazuje **wysoce prawoskośny** rozkład, gdzie większość obserwacji znajduje się poniżej **50**.  
- Linia rozkładu normalnego podkreśla duże odchylenie od symetrii, co sugeruje, że większość lokalizacji ma ograniczoną liczbę punktów użyteczności publicznej, natomiast pojedyncze przypadki z bardzo dużymi wartościami (powyżej **100**) są wyjątkami.

**[schoolDistance](#schoolDistancePlot)**  
- Rozkład odległości jest **prawoskośny**, z dominacją wartości **0-1 km**.  
- Linia normalna nie pasuje do rozkładu, co wskazuje na silną koncentrację danych blisko **0 km**.  
- Wartości odstające powyżej **3 km** sugerują lokalizacje z ograniczonym dostępem do szkół.

**[clinicDistance](#clinicDistancePlot)**  
- Histogram pokazuje **prawoskośny rozkład**, z większością wartości w przedziale **do 1 km**.  
- Linia rozkładu normalnego wyraźnie nie oddaje koncentracji danych w niższych wartościach.  
- Wartości powyżej **3 km** sugerują trudniejszy dostęp do opieki zdrowotnej w mniej zurbanizowanych obszarach.

**[postOfficeDistance](#postOfficeDistancePlot)**  
- Rozkład jest **prawoskośny**, z typowymi wartościami **0,5–1 km**.  
- Linia rozkładu normalnego wskazuje na istotne odchylenie od normalności, co podkreśla silne skupienie danych w niższych przedziałach.

**[restaurantDistance](#restaurantDistancePlot)**  
- Histogram ujawnia koncentrację wartości w zakresie **do 1 km** z pojedynczymi przypadkami powyżej **3 km**.  
- Przesunięcie względem linii normalnej podkreśla ograniczoną liczbę nieruchomości o znacznej odległości od restauracji.

**[collegeDistance](#collegeDistancePlot)**  
- Wartości typowe mieszczą się w przedziale **1–2 km**, natomiast histogram jest **lekko prawoskośny**.  
- Linia rozkładu normalnego dobrze przybliża dane w środkowej części, jednak widać odchylenia w wyższych wartościach (powyżej **4 km**).

**[pharmacyDistance](#pharmacyDistancePlot)** 
- Histogram jest **silnie prawoskośny**, z wartościami typowymi **do 1 km**.  
- Linia normalna nie jest dopasowana, co sugeruje, że rozkład empiryczny jest skupiony na jednym krańcu.

---

**[squareMeters](#squareMetersPlot)** 
- Rozkład powierzchni mieszkań jest **prawoskośny**, z wartościami dominującymi w przedziale **40–80 m²**.  
- Linia rozkładu normalnego sugeruje większą symetrię niż istnieje w danych.  
- **Wartości odstające** powyżej **100 m²** wskazują na duże apartamenty, które są nietypowe.

**[price](#pricePlot)**
- Histogram jest **wysoce prawoskośny**, z typowymi cenami **500 tys. – 1 mln zł**.  
- Rozkład empiryczny jest znacznie przesunięty względem linii normalnej, co podkreśla nierównomierną strukturę cen na rynku.

**[floor](#floorPlot)** 
- Większość mieszkań znajduje się na **1-5 piętrze**.  
- Linia rozkładu normalnego odbiega od rzeczywistego kształtu, który jest **skośny**, z kilkoma wartościami odstającymi powyżej **15 piętra**.

**[floorCount](#floorCountPlot)** 
- Rozkład pokazuje, że typowe budynki mają **4-6 pięter**.  
- Linia normalna nie oddaje koncentracji w niskich wartościach oraz odstępstw w wysokich budynkach.

**[buildingAge](#buildingAgePlot)** 
- Histogram wskazuje, że większość budynków ma mniej niż **50 lat**.  
- Rozkład jest prawoskośny, a linia normalna sugeruje większą symetrię niż rzeczywiście istnieje.

**[buildYear](#buildYearPlot)** 
- Rozkład pokazuje koncentrację budynków wybudowanych po **1950 roku**.  
- Linia normalna dobrze dopasowuje się do danych, jednak rozkład jest lekko przesunięty ku nowszym budynkom.

---
 
Analiza histogramów, w połączeniu z linią rozkładu normalnego, dostarczyła następujących wniosków:

- **Większość rozkładów jest prawoskośna**, co sugeruje koncentrację wartości w niższych przedziałach oraz obecność kilku wartości odstających.  
- Linie normalne pozwoliły zidentyfikować rozbieżności między rozkładami empirycznymi a teoretycznym rozkładem normalnym.  
- **Wartości odstające** są widoczne w wielu zmiennych, zwłaszcza w powierzchni mieszkań, cenach oraz odległościach do punktów użyteczności publicznej.  

Wyniki te potwierdzają specyfikę rynku nieruchomości, gdzie typowe wartości są skoncentrowane w określonych zakresach, a odstępstwa wskazują na szczególne przypadki, które mogą być analizowane osobno.

### Z-score

```{r z-score, echo = FALSE}
# mean((dane$buildYear-mean(dane$buildYear))/sd(dane$buildYear))
# mean((dane$price-mean(dane$price))/sd(dane$price))
# mean((dane$squareMeters-mean(dane$squareMeters))/sd(dane$squareMeters))
# mean((dane$pricePerSquareMeter-mean(dane$pricePerSquareMeter))/sd(dane$pricePerSquareMeter))
# mean((dane$rooms-mean(dane$rooms))/sd(dane$rooms))
# mean((dane$floor-mean(dane$floor))/sd(dane$floor))
# mean((dane$floorCount-mean(dane$floorCount))/sd(dane$floorCount))
# mean((dane$centreDistance-mean(dane$centreDistance))/sd(dane$centreDistance))
# mean((dane$buildingAge-mean(dane$buildingAge))/sd(dane$buildingAge))
# mean((dane$schoolDistance-mean(dane$schoolDistance))/sd(dane$schoolDistance))
# mean((dane$clinicDistance-mean(dane$clinicDistance))/sd(dane$clinicDistance))
# mean((dane$postOfficeDistance-mean(dane$postOfficeDistance))/sd(dane$postOfficeDistance))
# mean((dane$kindergartenDistance-mean(dane$kindergartenDistance))/sd(dane$kindergartenDistance))
# mean((dane$restaurantDistance-mean(dane$restaurantDistance))/sd(dane$restaurantDistance))
# mean((dane$collegeDistance-mean(dane$collegeDistance))/sd(dane$collegeDistance))
# mean((dane$pharmacyDistance-mean(dane$pharmacyDistance))/sd(dane$pharmacyDistance))
# mean((dane$poiCount-mean(dane$poiCount))/sd(dane$poiCount))
```


```{r tab_zscore, results='asis', eval=TRUE, echo=FALSE}

wyniki <- data.frame(
  Zmienna = c("buildYear", "price", "squareMeters", "pricePerSquareMeter", "rooms",
              "floor", "floorCount", "centreDistance", "buildingAge", "schoolDistance",
              "clinicDistance", "postOfficeDistance", "kindergartenDistance", 
              "restaurantDistance", "collegeDistance", "pharmacyDistance", "poiCount"),
  Wartosc = c("1.321569e-15", "9.155718e-17", "3.0552e-17", "-5.888089e-17", "-1.961117e-16",
              "-3.274304e-17", "-9.234339e-17", "-1.348539e-16", "8.221441e-17", "1.247826e-17",
             " 2.77439e-17", "9.446714e-17", "-4.220434e-17", "5.62074e-17", "-2.656712e-17",
              "-1.519166e-17", "-2.97876e-17")
)
knitr::kable(wyniki, caption = "Wyniki Z-Score")
```

<p style="text-align: justify;">
Standaryzacja przy użyciu z-score umożliwia identyfikację wartości odstających. Wartości, które są znacznie większe lub mniejsze niż 3 odchylenia standardowe, mogą być traktowane jako odstające. Zastosowanie z-score zapewniło, że wszystkie analizowane zmienne są zbalansowane wokół średniej, co stanowi podstawę do dalszych, bardziej szczegółowych analiz. Większość wartości w danych jest symetrycznie rozłożona wokół średniej i nie dominuje żaden zbiór ekstremalnych wartości.
</p>

### Transformacje



```{r transformacja_price, echo = FALSE, fig.height=4, fig.width=8}
par(mfrow = c(1,2))
# price
# wykres przed transformacją
hist(na.omit(dane$price), 
     probability = TRUE, 
     col = "antiquewhite", 
     main = "Original: Histogram - price", 
     xlab = "price")
curve(dnorm(x, mean = mean(na.omit(dane$price)), 
            sd = sd(na.omit(dane$price))), 
      col = "indianred2", 
      lwd = 2, 
      add = TRUE)

# po transformacji
dane$price <- log(dane$price)
hist(na.omit(dane$price), 
     probability = TRUE, 
     col = "antiquewhite", 
     main = "Histogram - log(price)", 
     xlab = "price")
curve(dnorm(x, mean = mean(na.omit(dane$price)), 
            sd = sd(na.omit(dane$price))), 
      col = "indianred2", 
      lwd = 2, 
      add = TRUE)

```





```{r transformacja_PricePerSquareMeter, echo = FALSE, fig.height=4, fig.width=8}
par(mfrow = c(1,2))
# poiCount
# wykres przed transformacją
hist(na.omit(dane$poiCount), 
     probability = TRUE, 
     col = "goldenrod1", 
     main = "Original: Histogram - poiCount", 
     xlab = "poiCount")
curve(dnorm(x, mean = mean(na.omit(dane$poiCount)), 
            sd = sd(na.omit(dane$poiCount))), 
      col = "darkblue", 
      lwd = 2, 
      add = TRUE)

# po transformacji
dane$poiCount <- log(dane$poiCount + 1)
hist(na.omit(dane$poiCount), 
     probability = TRUE, 
     col = "goldenrod1", 
     main = "Histogram - log(poiCount+1)", 
     xlab = "poiCount")
curve(dnorm(x, mean = mean(dane$poiCount), 
            sd = sd(na.omit(dane$poiCount))), 
      col = "darkblue", 
      lwd = 2, 
      add = TRUE)

```

#### Transformacja zmiennej price oraz poiCount

##### Powody przeprowadzenia transformacji logarytmicznej:
1. **Zmniejszenie wpływu wartości odstających**: 
   - W zmiennych takich jak **price** i **poiCount** występują duże wartości odstające. Dla ceny może to być kilka luksusowych apartamentów o bardzo wysokiej cenie, a dla liczby punktów zainteresowania miejsca z wyjątkowo dużą liczbą udogodnień w okolicy. Transformacja logarytmiczna zmniejsza wpływ tych skrajnych wartości na analizy.
   
2. **Poprawa rozkładu zmiennych**: 
   - Cena mieszkań oraz liczba punktów zainteresowania często mają rozkład prawoskośny, co oznacza, że większość wartości jest skupiona przy niższych wartościach, ale pojawiają się też wyższe, rzadkie wartości. Logarytm zmniejsza tę asymetrię, zbliżając dane do rozkładu normalnego, co ułatwia interpretację i modelowanie statystyczne.

##### Interpretacja:
Po transformacji:
- **Rozkład zmiennej price** jest bardziej symetryczny, co ułatwi modelowanie zależności między ceną a innymi zmiennymi.
- **Rozkład zmiennej poiCount** jest  mniej skośny, co pozwoli lepiej zrozumieć wpływ liczby punktów zainteresowania na analizowane wyniki.



#### Uzasadnienie braku transformacji dla poszczególnych kolumn

1. **squareMeters**  
   - **Uzasadnienie**: Duże wartości tej zmiennej (np. powyżej 200 m²) mogą odnosić się do apartamentów luksusowych lub przestronnych domów, co jest zrozumiałe w kontekście rynku nieruchomości. Asymetria rozkładu wynika z faktu, że małe mieszkania są bardziej powszechne, ale większe jednostki wciąż mają naturalne uzasadnienie.  

2. **rooms**  
   - **Uzasadnienie**: Liczba pokoi w mieszkaniach czy domach jest zwykle niewielka i wynika z ich przeznaczenia. Duże liczby (np. 7–10 pokoi) mogą odnosić się do dużych domów jednorodzinnych lub luksusowych apartamentów. Każda wartość zmiennej ma swoje logiczne wyjaśnienie.  

3. **floor oraz floorCount**  
   - **Uzasadnienie**: Wysokie wartości (np. powyżej 10. piętra) zazwyczaj odnoszą się do mieszkań w wieżowcach, co jest typowe w dużych miastach. Rozkład zmiennej jest zgodny z różnorodnością rynku.  

5. **buildYear**  
   - **Uzasadnienie**: Starsze budynki (np. przedwojenne) mają swoje unikalne cechy (np. kamienice), a nowe budynki charakteryzują nowoczesne technologie i standardy. Każda wartość zmiennej niesie ze sobą istotny kontekst historyczny i architektoniczny.  

6. **centreDistance**  
   - **Uzasadnienie**: Duże odległości (np. >20 km) zwykle oznaczają mieszkania na przedmieściach lub w miejscowościach satelickich, co jest naturalne w kontekście urbanistycznym. Mniejsze wartości wskazują na nieruchomości w centrum miasta, co również ma sens.  

8. **schoolDistance**  
   - **Uzasadnienie**: Krótsze odległości są typowe dla osiedli mieszkaniowych, gdzie szkoły są blisko mieszkańców. Większe odległości mogą dotyczyć obszarów wiejskich lub mniej zurbanizowanych.  

9. **clinicDistance**  
   - **Uzasadnienie**: Podobnie jak w przypadku szkół, krótsze odległości charakteryzują gęsto zabudowane obszary, a większe – mniej rozwinięte okolice. Rozkład zmiennej jest zgodny z rzeczywistością.  

10. **postOfficeDistance**  
    - **Uzasadnienie**: Odległości te odzwierciedlają rzeczywisty dostęp do infrastruktury. Krótsze odległości oznaczają bardziej zurbanizowane tereny, a dłuższe – obszary mniej zaludnione.  

11. **kindergartenDistance**  
    - **Uzasadnienie**: Podobnie jak w przypadku szkół, odległości mają naturalne wyjaśnienie w charakterystyce lokalizacji.  

12. **restaurantDistance**  
    - **Uzasadnienie**: Krótsze odległości są typowe dla centrów miast, a większe – dla terenów podmiejskich i wiejskich. Zmienna w swojej formie jest wystarczająco zrozumiała.  

13. **collegeDistance**  
    - **Uzasadnienie**: Podobnie jak inne odległości, wartości tej zmiennej mają naturalne uzasadnienie w zależności od lokalizacji nieruchomości względem centrów edukacyjnych.  

14. **pharmacyDistance**  
    - **Uzasadnienie**: Odległości te są intuicyjne i w pełni odpowiadają rzeczywistości. Apteki są zlokalizowane bliżej mieszkańców w gęsto zaludnionych obszarach, co tłumaczy krótsze wartości.  

15. **buildingAge**  
    - **Uzasadnienie**: Starsze budynki (np. >50 lat) są często kamienicami lub historycznymi budynkami, a nowe (np. <10 lat) to inwestycje deweloperskie. Wiek budynku jest intuicyjny i łatwy do zrozumienia bez transformacji.  


**Podsumowanie**: Brak transformacji dla większości zmiennych wynika z ich naturalnego znaczenia w kontekście rynku nieruchomości. Transformacje stosujemy wyłącznie w sytuacjach, gdy poprawiają one analizę, bez utraty interpretowalności. W przypadku tych zmiennych, zachowanie ich w pierwotnej formie pozwala na lepsze oddanie rzeczywistości i kontekstu analizy.


```{r walidacja_i_weryfikacja_logicznej_spójności_danych, echo=FALSE, out.width="83%", fig.width=14, fig.height=9}

# Walidacja wcześniej zdefiniowanych reguł 

rules <- validator(
  "Floor>FloorCount" = floor <= floorCount,                                              # Piętro nie większe niż liczba kondygnacji
  "BuildYear<=2024" = buildYear <= 2024,                                                 # Rok budowy nie większy niż rok bieżący
  "BuildYear>1600" = buildYear > 1600,                                                   # Rok budowy późniejszy niż 1600
  "Floor>=0" = floor >= 0,                                                               # Piętro nie może być ujemne
  "FloorCount>= 0" = floorCount >= 0,                                                    # Liczba kondygnacji nie może być ujemna
  "Rooms>0" = rooms > 0,                                                                 # Liczba pokoi większa niż 0
  "Rooms<= 15" = rooms <= 15,                                                            # Liczba pokoi nie większa niż 15
  "Elevator in a building with 0 floors" = !(floorCount == 0 & hasElevator == "yes")     # Sprawdzenie, czy budynek z 0 kondygnacjami ma windę
)

out <- confront(dane, rules)

rules_names <- c("Floor > Floor Count", "Build Year <= 2024", "Build Year > 1600", 
                 "Floor >= 0", "Floor Count >= 0", "Rooms > 0", "Rooms <= 15", "Elevator in a building with 0 floors")

expressions <- c("Floor <= Floor Count", "Build Year <= 2024", "Build Year > 1600", 
                 "Floor >= 0", "Floor Count >= 0", "Rooms > 0", "Rooms <= 15", "!(floorCount == 0 & hasElevator == 'yes')")

results <- lapply(c("Floor > Floor Count", "Build Year <= 2024", "Build Year > 1600", 
                    "Floor >= 0", "Floor Count >= 0", "Rooms > 0", "Rooms <= 15", "Elevator in a building with 0 floors"), 
                  function(x) out$`._value`[[x]])


passes <- sapply(results_logical, sum)
nNA <- sapply(results_logical, function(x) sum(!x))  

# Przygotowanie wyników walidacji
validation_results <- data.frame(
  rule = rules_names,
  examined_observations = rep(21501, 8),
  observations_passing_rule = passes,
  observations_failing_rule = nNA,
  rule_expression = expressions
)

# Wykres wyników walidacji z podziałem na reguły
plot(out)

```

<p style="text-align: justify;">
W procesie walidacji danych większość reguł została spełniona, jednak w przypadku jednej reguły, dotyczącej zgodności zmiennych floor i floorCount, wykryto 545 nieprawidłowych obserwacji, które wymagają dalszej analizy i korekty. Zgodnie z regułą, wartości floor nie powinny przekraczać wartości floorCount, co jest kluczowe dla spójności danych. Pozostałe reguły zostały prawidłowo zastosowane i nie wykryto żadnych innych istotnych problemów w analizowanych danych.
</p>

<p style="text-align: justify;">
Przed rozpoczęciem walidacji brakujące wartości (NA) zostały uzupełnione, co pozwoliło na przeprowadzenie pełnej analizy zgodności z regułami. Imputacja brakujących danych była kluczowym krokiem, umożliwiającym dalsze etapy weryfikacji danych.
</p>

<p style="text-align: justify;">
Błędy w danych floor i floorCount mogą wynikać z błędnie uzupełnionych wartości lub nieaktualnych danych (budynki mogły zmienić liczbę kondygnacji po modernizacji).
</p>

```{r weryfikacja_cz.2, wykres_kołowy_dla_obserwacji, echo=FALSE, fig.width=13, fig.height=7}

# Wykres kołowy dla obserwacji "Piętro > liczba kondygnacji"
data <- data.frame(
  category = c("Spełniające regułę", "Niespełniające reguły"),
  count = c(20956, 545)
)

ggplot(data, aes(x = " ", y = count, fill = category)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Floor > Floor Count") +
  theme_minimal() +
  theme(
    axis.text = element_blank(), 
    axis.ticks = element_blank(), 
    plot.title = element_text(hjust = 0.5, size = 30, face = "bold"),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    legend.title = element_blank(),
    legend.text = element_text(size = 19),
    plot.margin = margin(30, 30, 30, 30),
    panel.grid = element_blank(),
    panel.border = element_blank()
  ) +
  geom_text(aes(label = paste0(count, " (", round(count / sum(count) * 100, 1), "%)")),
            color = "black", size = 8, fontface = "bold", 
            position = position_stack(vjust = 0.7)) +
  scale_fill_manual(values = c("darkseagreen", "powderblue"))

```

```{r walidacja_i_korekta_wartości;floor_floorCount,flitracja_duplikatów, echo=FALSE}

# Błędne obserwacje - filtracja 
invalid_observations <- dane %>% filter(floor > floorCount)

# Korekta błędnych wartości
dane <- dane %>% mutate(floorCount = ifelse(floorCount < floor, floor, floorCount))

# Sprawdzanie duplikatów
duplicates <- dane[duplicated(dane), ]

```

<p style="text-align: justify;">
W wyniku analizy danych stwierdzono, że w niektórych przypadkach wartość floor była większa niż liczba floorCount, co jest logicznie nieprawidłowe. Aby poprawić te błędy, przyjęto zasadę, że w takich sytuacjach wartość liczby kondygnacji (floorCount) zostanie ustawiona na wartość piętra (floor).

Jeśli wartość liczby kondygnacji była równa lub większa od wartości piętra, dane pozostały niezmienione. Taka korekta zapewnia spójność danych i eliminuje przypadki, w których piętro przewyższa liczbę kondygnacji w budynku.Nie znaleziono duplikatów wierszy w danych. 
</p>

```{r dodanie_nowych_danych, echo=FALSE, message=FALSE, warning=FALSE}
# Wczytanie granic administracyjnych województw
gml_file <- "ms_A01_Granice_wojewodztw.gml"

# Ukrycie komunikatów st_read
invisible(capture.output({
  wojewodztwa <- st_read(gml_file)
}))

# Tworzenie punktów z danych (longitude i latitude)
punkty <- st_as_sf(dane, coords = c("longitude", "latitude"), crs = 4326)

# Dopasowanie układu współrzędnych punktów do układu pliku GML
punkty <- st_transform(punkty, st_crs(wojewodztwa))

# Dopasowanie punktów do granic województw
dane_with_region <- st_join(punkty, wojewodztwa)

# Dodanie kolumny 'wojewodztwo' na podstawie JPT_NAZWA_
dane$wojewodztwo <- dane_with_region$JPT_NAZWA_

# Obliczenie średniej ceny za metr kwadratowy na województwo
srednie_ceny_m2 <- dane %>%
  group_by(wojewodztwo) %>%
  summarise(srednia_cena_m2 = mean(pricePerSquareMeter, na.rm = TRUE))

# Połączenie danych o cenach z granicami województw
wojewodztwa <- wojewodztwa %>%
  left_join(srednie_ceny_m2, by = c("JPT_NAZWA_" = "wojewodztwo"))

# Obliczenie centroidów województw dla etykiet
wojewodztwa_centroidy <- suppressWarnings({
  wojewodztwa %>%
    st_centroid() %>%
    mutate(label = JPT_NAZWA_)
})
```

# Analiza średnich cen mieszkań według województw

<p style="text-align: justify;"> Celem analizy regionalnej cen mieszkań jest zrozumienie zróżnicowania poziomu cen nieruchomości w Polsce. Wykorzystanie mapy województw pozwala zobrazować różnice w średnich cenach za metr kwadratowy w poszczególnych regionach kraju. Tego rodzaju wizualizacja umożliwia identyfikację obszarów o najwyższych oraz najniższych cenach, co może stanowić punkt wyjścia do dalszej analizy rynku nieruchomości, uwzględniającej czynniki wpływające na cenę, takie jak urbanizacja, poziom dochodów czy lokalna infrastruktura. </p>




```{r wykres_choropleth, echo=FALSE, message=FALSE, warning=FALSE}
# Tworzenie mapy choropleth
ggplot(data = wojewodztwa) +
  geom_sf(aes(fill = srednia_cena_m2), color = "black", size = 0.2) +
  scale_fill_gradient(name = "Śr. cena za m² (PLN)", 
                      low = "white", high = "red", na.value = "gray",
                      labels = label_number(big.mark = " ", decimal.mark = ",")) +
  geom_sf_text(data = wojewodztwa_centroidy, aes(label = label), size = 3, color = "black") +
  theme_minimal() +
  labs(title = "Średnia cena za m² w Polsce według województw",
       caption = "Źródło: https://www.geoportal.gov.pl/") +
  theme(legend.position = "right")
```


#### **Interpretacja wyników**

##### **Województwo mazowieckie jako lider cenowy**
<p style="text-align: justify;">Z wykresu wynika, że województwo mazowieckie, w szczególności Warszawa, dominuje pod względem średnich cen za metr kwadratowy, osiągając wartości powyżej **18 000 PLN/m²**. Jest to odzwierciedleniem centralnej roli stolicy w gospodarce, jej rozwiniętego rynku pracy oraz wysokiego popytu na mieszkania.</p>
##### **Regiony o najniższych cenach**
<p style="text-align: justify;">Województwa takie jak podkarpackie, lubelskie i podlaskie charakteryzują się znacznie niższymi cenami, oscylującymi wokół **10 000 PLN/m²**. Są to regiony o mniejszym stopniu urbanizacji oraz niższym popycie na nieruchomości w porównaniu do dużych miast.</p>
##### **Regiony o średnich cenach**
<p style="text-align: justify;">Województwa dolnośląskie, pomorskie i wielkopolskie znajdują się w średnim przedziale cenowym, wynoszącym od **12 000 PLN/m² do 16 000 PLN/m²**. Obejmują one dynamicznie rozwijające się miasta, takie jak Wrocław, Gdańsk czy Poznań, które są istotnymi ośrodkami akademickimi i biznesowymi.</p>
##### **Różnice między regionami**
<p style="text-align: justify;">Mapa podkreśla wyraźne różnice w rozwoju regionalnym. Województwa takie jak opolskie czy świętokrzyskie należą do najtańszych, co może być związane z niższym stopniem urbanizacji, mniejszym popytem oraz ograniczoną dostępnością pracy w tych regionach.</p>

#### **Wnioski**
<p style="text-align: justify;"> Wykres średnich cen mieszkań za metr kwadratowy w podziale na województwa jasno pokazuje istotne różnice regionalne. Najwyższe ceny dominują w centralnej i północno-zachodniej części Polski, szczególnie w miastach takich jak Warszawa, Wrocław, Gdańsk i Kraków. Natomiast regiony wschodnie oraz mniej zurbanizowane województwa charakteryzują się niższymi cenami, co wskazuje na ich mniejszy potencjał rynkowy. Wyniki te sugerują, że dalsze badania powinny uwzględnić czynniki demograficzne, ekonomiczne i infrastrukturalne, które kształtują rynek nieruchomości w Polsce. </p>




```{r, results='asis', eval=TRUE, echo=FALSE, comment=FALSE, warning=FALSE}

get_mode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

statystyki <- dane %>%
  group_by(city) %>%
  summarise(
    "Średnia powierzchnia" = mean(squareMeters, na.rm = TRUE),
    "Średnia cena za $m^2$" = mean(pricePerSquareMeter, na.rm = TRUE),
    "Najczęstsza liczba pokoi" = get_mode(rooms)
  )

knitr::kable(statystyki, caption = "Poszczególne statystyki dla miast")
```



# **Analiza udogodnień w nieruchomościach**

```{r, echo=FALSE, fig.height=10,fig.width=10}
p1 <- ggplot(dane, aes(x = hasBalcony, y = price)) +
  geom_boxplot(fill = c("lightblue", "lightgreen")) +
  labs(title = "Wpływ obecności balkonu na cenę mieszkania",
       x = "Czy mieszkanie ma balkon?",
       y = "Cena (PLN)") +
  theme_minimal()

p2 <- ggplot(dane, aes(x = hasElevator, y = price)) +
  geom_boxplot(fill = c("plum", "peachpuff")) +
  labs(title = "Wpływ obecności windy na cenę mieszkania",
       x = "Czy mieszkanie ma windę?",
       y = "Cena (PLN)") +
  theme_minimal()

p3 <- ggplot(dane, aes(x = hasParkingSpace, y = price)) +
  geom_boxplot(fill = c("lightyellow", "tomato2")) +
  labs(title = "Wpływ obecności parkingu na cenę mieszkania",
       x = "Czy mieszkanie ma parking?",
       y = "Cena (PLN)") +
  theme_minimal()

p4 <- ggplot(dane, aes(x = hasSecurity, y = price)) +
  geom_boxplot(fill = c("thistle", "darkslateblue")) +
  labs(title = "Wpływ obecności ochrony na cenę mieszkania",
       x = "Czy mieszkanie ma ochronę?",
       y = "Cena (PLN)") +
  theme_minimal()

p5 <- ggplot(dane, aes(x = hasStorageRoom, y = price)) +
  geom_boxplot(fill = c("lightsalmon1", "darkseagreen3")) +
  labs(title = "Wpływ obecności komórki lokatorskiej na cenę mieszkania",
       x = "Czy mieszkanie ma komórke lokatorską?",
       y = "Cena (PLN)") +
  theme_minimal()

grid.arrange(p1, p2, p3, p4, p5, nrow =3)

```


#### Interpretacja wyników analizy wpływu obecności balkonu na cenę mieszkań:

W analizie porównaliśmy ceny mieszkań w dwóch grupach: z balkonem oraz bez balkonu. Obserwacje z wykresów pudełkowych wskazują, że poziomy mediany w obu grupach są podobne, co sugeruje, że obecność balkonu nie ma znaczącego wpływu na centralną tendencję ceny mieszkań.

Jednakże mediana w grupie mieszkań z balkonem jest nieco wyższa niż w grupie bez balkonu, co może wskazywać na minimalną przewagę cenową mieszkań wyposażonych w to udogodnienie. Dodatkowo pudełko w tej grupie (symbolizujące zakres między dolnym a górnym kwartylem) jest węższe, co oznacza mniejsze zróżnicowanie cen wśród mieszkań z balkonem.

Z kolei grupa mieszkań bez balkonu charakteryzuje się szerszym pudełkiem, co sugeruje większą zmienność cen. Może to wynikać z różnorodności innych czynników wpływających na cenę, które w tej grupie mają większe znaczenie.


```{r, echo=FALSE, comment=FALSE, warning=FALSE}
pokoejecenam2 <- dane %>%
  group_by(city, rooms) %>%
  summarise(
    mean_price_per_m2 = mean(pricePerSquareMeter, na.rm = TRUE)
  )

podsumowanie_m2dlamiast <- dane %>%
  group_by(city) %>%
  summarise(
    mean_price_per_m2 = mean(pricePerSquareMeter, na.rm = TRUE)
  )
top5 <- podsumowanie_m2dlamiast %>%
  arrange(desc(mean_price_per_m2)) %>%
  slice_head(n = 5)

top5pokojecenamiasta <- pokoejecenam2 %>% filter(city %in% top5$city)

```




```{r, echo=FALSE, comment=FALSE, warning=FALSE}
barplot_city <- plot_ly(
  data = top5pokojecenamiasta,
  x = ~rooms,
  y = ~mean_price_per_m2,
  color = ~city, 
  type = "bar"
) %>%
  layout(
    title = "Średnia cena za m^2 w zależności od liczby pokoi i miasta",
    xaxis = list(title = "Liczba pokoi"),
    yaxis = list(title = "Średnia cena za $m^2$ [PLN]"),
    barmode = "group",
    legend = list(title = list(text = "Miasto"))
  )

barplot_city

```






